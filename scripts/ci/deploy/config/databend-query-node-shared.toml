# Usage:
# databend-query -c databend_query_config_spec.toml

[query]
max_active_sessions = 256
wait_timeout_mills = 5000

# For flight rpc.
flight_api_address = "0.0.0.0:59091"

# Databend Query http address.
# For admin RESET API.
admin_api_address = "0.0.0.0:58080"

# Databend Query metrics RESET API.
metric_api_address = "0.0.0.0:57070"

# Databend Query MySQL Handler.
mysql_handler_host = "0.0.0.0"
mysql_handler_port = 53307

# Databend Query ClickHouse Handler.
clickhouse_http_handler_host = "0.0.0.0"
clickhouse_http_handler_port = 58124

# Databend Query HTTP Handler.
http_handler_host = "0.0.0.0"
http_handler_port = 58000

tenant_id = "shared_tenant"
cluster_id = "test_cluster"

table_engine_memory_enabled = true
database_engine_github_enabled = true

table_cache_enabled = true
table_memory_cache_mb_size = 1024
table_disk_cache_root = "_cache"
table_disk_cache_mb_size = 10240
table_cache_bloom_index_meta_count=3000
table_cache_bloom_index_data_bytes=1073741824

share_endpoint_address = "127.0.0.1:33003" # receive shared information from open sharing
# [[query.users]]
# name = "admin"
# auth_type = "no_password"

# [[query.users]]
# name = "databend"
# auth_type = "double_sha1_password"
# # echo -n "databend" | sha1sum | cut -d' ' -f1 | xxd -r -p | sha1sum
# auth_string = "3081f32caef285c232d066033c89a78d88a6d8a5"

# [[query.users]]
# name = "datafuselabs"
# auth_type = "sha256_password"
# #  echo -n "datafuselabs" | sha256sum
# auth_string = "6db1a2f5da402b43c066fcadcbf78f04260b3236d9035e44dd463f21e29e6f3b"


[log]

[log.file]
level = "ERROR"
format = "text"
dir = "./.databend/logs_1"

[meta]
endpoints = ["0.0.0.0:9191"]
username = "root"
password = "root"
client_timeout_in_second = 60
auto_sync_interval = 60

# Storage config.
[storage]
# fs | s3 | azblob | obs | oss
type = "fs"

# Set a local folder to store your data.
# Comment out this block if you're NOT using local file system as storage.
[storage.fs]
data_path = "./.databend/stateless_test_data"

# To use S3-compatible object storage, uncomment this block and set your values.
# [storage.s3]
# bucket = "<your-bucket-name>"
# endpoint_url = "<your-endpoint>"
# access_key_id = "<your-key-id>"
# secret_access_key = "<your-account-key>"
# enable_virtual_host_style = false

# To use Azure Blob storage, uncomment this block and set your values.
# [storage.azblob]
# endpoint_url = "https://<your-storage-account-name>.blob.core.windows.net"
# container = "<your-azure-storage-container-name>"
# account_name = "<your-storage-account-name>"
# account_key = "<your-account-key>"

# To use OBS object storage, uncomment this block and set your values.
# [storage.obs]
# bucket = "<your-bucket-name>"
# endpoint_url = "<your-endpoint>"
# access_key_id = "<your-key-id>"
# secret_access_key = "<your-account-key>"

# To use OSS object storage, uncomment this block and set your values.
# [storage.oss]
# bucket = "<your-bucket-name>"
# endpoint_url = "<your-endpoint>"
# access_key_id = "<your-key-id>"
# access_key_secret = "<your-account-key>"
