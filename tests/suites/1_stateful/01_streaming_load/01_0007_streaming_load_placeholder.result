>>>> create or replace stage streaming_load_07 url='fs:///tmp/streaming_load_07/';
>>>> CREATE or replace TABLE streaming_load_07 (c1 string default 'ok', c2 int, c3 string, c4 date);
--csv
>>>> copy into @streaming_load_07/data.csv from (select '2020-01-02' as c4, 110 as c2) file_format=(type='csv')  single=true include_query_id=false use_raw_path=true detailed_output=true overwrite=true;
data.csv	17	1
+ curl -sS -H x-databend-query-id:load-csv -H 'sql:insert into streaming_load_07(c3, c4, c2) values ('\''a'\'', ?, ?) file_format = (type=csv)' -F upload=@/tmp/streaming_load_07/data.csv -u root: -XPUT http://localhost:8000/v1/streaming_load
{"id":"loadcsv","stats":{"rows":1,"bytes":39}}
<<<<
>>>> select * from streaming_load_07;
ok	110	a	2020-01-02
<<<<
>>>> truncate table streaming_load_07
--tsv
>>>> copy into @streaming_load_07/data.tsv from (select '2020-01-02' as c4, 110 as c2) file_format=(type='tsv')  single=true include_query_id=false use_raw_path=true detailed_output=true overwrite=true;
data.tsv	15	1
+ curl -sS -H x-databend-query-id:load-tsv -H 'sql:insert into streaming_load_07(c3, c4, c2) values ('\''a'\'', ?, ?) file_format = (type=tsv)' -F upload=@/tmp/streaming_load_07/data.tsv -u root: -XPUT http://localhost:8000/v1/streaming_load
{"id":"loadtsv","stats":{"rows":1,"bytes":39}}
<<<<
>>>> select * from streaming_load_07;
ok	110	a	2020-01-02
<<<<
>>>> truncate table streaming_load_07
--ndjson
>>>> copy into @streaming_load_07/data.ndjson from (select '2020-01-02' as c4, 110 as c2) file_format=(type='ndjson')  single=true include_query_id=false use_raw_path=true detailed_output=true overwrite=true;
data.ndjson	29	1
+ curl -sS -H x-databend-query-id:load-ndjson -H 'sql:insert into streaming_load_07(c3, c4, c2) values ('\''a'\'', ?, ?) file_format = (type=ndjson)' -F upload=@/tmp/streaming_load_07/data.ndjson -u root: -XPUT http://localhost:8000/v1/streaming_load
{"id":"loadndjson","stats":{"rows":1,"bytes":39}}
<<<<
>>>> select * from streaming_load_07;
ok	110	a	2020-01-02
<<<<
>>>> truncate table streaming_load_07
--parquet
>>>> copy into @streaming_load_07/data.parquet from (select '2020-01-02' as c4, 110 as c2) file_format=(type='parquet')  single=true include_query_id=false use_raw_path=true detailed_output=true overwrite=true;
data.parquet	665	1
+ curl -sS -H x-databend-query-id:load-parquet -H 'sql:insert into streaming_load_07(c3, c4, c2) values ('\''a'\'', ?, ?) file_format = (type=parquet)' -F upload=@/tmp/streaming_load_07/data.parquet -u root: -XPUT http://localhost:8000/v1/streaming_load
{"id":"loadparquet","stats":{"rows":1,"bytes":39}}
<<<<
>>>> select * from streaming_load_07;
ok	110	a	2020-01-02
<<<<
>>>> truncate table streaming_load_07
>>>> drop table if exists streaming_load_07
