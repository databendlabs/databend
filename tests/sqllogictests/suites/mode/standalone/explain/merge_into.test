statement ok
set enable_experimental_merge_into = 1;

statement ok
DROP TABLE IF EXISTS employees2;

statement ok
DROP TABLE IF EXISTS salaries2;

statement ok
CREATE TABLE employees2 (employee_id INT, employee_name VARCHAR(255),department VARCHAR(255));

statement ok
CREATE TABLE salaries2 (employee_id INT,salary DECIMAL(10, 2));

statement ok
INSERT INTO employees2 VALUES(1, 'Alice', 'HR'),(2, 'Bob', 'IT'),(3, 'Charlie', 'Finance'),(4, 'David', 'HR');

statement ok
INSERT INTO salaries2 VALUES(1, 50000.00),(2, 60000.00);

query TT
MERGE INTO salaries2 USING (SELECT * FROM employees2) as employees2 ON salaries2.employee_id = employees2.employee_id WHEN MATCHED AND employees2.department = 'HR' THEN UPDATE SET salaries2.salary = salaries2.salary + 1000.00 WHEN MATCHED THEN UPDATE SET salaries2.salary = salaries2.salary + 500.00 WHEN NOT MATCHED THEN INSERT (employee_id, salary) VALUES (employees2.employee_id, 55000.00);
----
2 2

## issue 16588
query T
explain merge into salaries2 using employees2 on 1 != 1 when matched AND employees2.department = 'HR' THEN UPDATE SET salaries2.salary = salaries2.salary + 1000.00 WHEN MATCHED THEN UPDATE SET salaries2.salary = salaries2.salary + 500.00 WHEN NOT MATCHED THEN INSERT (employee_id, salary) VALUES (employees2.employee_id, 55000.00)
----
CommitSink
└── DataMutation
    ├── target table: [catalog: default] [database: default] [table: salaries2]
    ├── matched delete: [condition: None]
    ├── unmatched insert: [condition: None, insert into (employee_id,salary) values(employees2.employee_id (#0),55000.00)]
    └── HashJoin
        ├── output columns: [employees2.employee_id (#0), employees2.employee_name (#1), employees2.department (#2), salaries2._row_id (#5)]
        ├── join type: LEFT OUTER
        ├── build keys: []
        ├── probe keys: []
        ├── keys is null equal: []
        ├── filters: []
        ├── estimated rows: 4.00
        ├── EmptyResultScan(Build)
        └── TableScan(Probe)
            ├── table: default.default.employees2
            ├── output columns: [employee_id (#0), employee_name (#1), department (#2)]
            ├── read rows: 4
            ├── read size: < 1 KiB
            ├── partitions total: 1
            ├── partitions scanned: 1
            ├── pruning stats: [segments: <range pruning: 1 to 1>, blocks: <range pruning: 1 to 1>]
            ├── push downs: [filters: [], limit: NONE]
            └── estimated rows: 4.00

query T
explain merge into salaries2 using employees2 on 1 != 1 when matched AND employees2.department = 'HR' THEN UPDATE SET salaries2.salary = salaries2.salary + 1000.00 WHEN MATCHED THEN UPDATE SET salaries2.salary = salaries2.salary + 500.00
----
EmptyResultScan

query T
explain MERGE INTO salaries2 USING (SELECT * FROM employees2) as employees2 ON salaries2.employee_id = employees2.employee_id WHEN MATCHED AND employees2.department = 'HR' THEN UPDATE SET salaries2.salary = salaries2.salary + 1000.00 WHEN MATCHED THEN UPDATE SET salaries2.salary = salaries2.salary + 500.00 WHEN NOT MATCHED THEN INSERT (employee_id, salary) VALUES (employees2.employee_id, 55000.00);
----
CommitSink
└── DataMutation
    ├── target table: [catalog: default] [database: default] [table: salaries2]
    ├── matched update: [condition: employees2.department (#2) = 'HR', update set salary = if(CAST(_predicate (#18446744073709551615) AS Boolean NULL), CAST(salaries2.salary (#4) + 1000.00 AS Decimal(10, 2) NULL), salaries2.salary (#4))]
    ├── matched update: [condition: None, update set salary = if(CAST(_predicate (#18446744073709551615) AS Boolean NULL), CAST(salaries2.salary (#4) + 500.00 AS Decimal(10, 2) NULL), salaries2.salary (#4))]
    ├── unmatched insert: [condition: None, insert into (employee_id,salary) values(employees2.employee_id (#0),55000.00)]
    └── RowFetch
        ├── output columns: [employees2.employee_id (#0), employees2.employee_name (#1), employees2.department (#2), salaries2.employee_id (#3), salaries2._row_id (#5), salaries2.salary (#4)]
        ├── columns to fetch: [salary]
        └── HashJoin
            ├── output columns: [employees2.employee_id (#0), employees2.employee_name (#1), employees2.department (#2), salaries2.employee_id (#3), salaries2._row_id (#5)]
            ├── join type: LEFT OUTER
            ├── build keys: [salaries2.employee_id (#3)]
            ├── probe keys: [employees2.employee_id (#0)]
            ├── keys is null equal: [false]
            ├── filters: []
            ├── estimated rows: 4.00
            ├── TableScan(Build)
            │   ├── table: default.default.salaries2
            │   ├── output columns: [employee_id (#3), _row_id (#5)]
            │   ├── read rows: 4
            │   ├── read size: < 1 KiB
            │   ├── partitions total: 1
            │   ├── partitions scanned: 1
            │   ├── pruning stats: [segments: <range pruning: 1 to 1>, blocks: <range pruning: 1 to 1>]
            │   ├── push downs: [filters: [], limit: NONE]
            │   └── estimated rows: 4.00
            └── TableScan(Probe)
                ├── table: default.default.employees2
                ├── output columns: [employee_id (#0), employee_name (#1), department (#2)]
                ├── read rows: 4
                ├── read size: < 1 KiB
                ├── partitions total: 1
                ├── partitions scanned: 1
                ├── pruning stats: [segments: <range pruning: 1 to 1>, blocks: <range pruning: 1 to 1>]
                ├── push downs: [filters: [], limit: NONE]
                └── estimated rows: 4.00

statement ok
INSERT INTO salaries2 VALUES(1, 50000.00),(2, 60000.00);

query T
explain MERGE INTO salaries2 USING (SELECT * FROM employees2) as employees2 ON salaries2.employee_id = employees2.employee_id WHEN MATCHED AND employees2.department = 'HR' THEN UPDATE SET salaries2.salary = salaries2.salary + 1000.00 WHEN MATCHED THEN UPDATE SET salaries2.salary = salaries2.salary + 500.00 WHEN NOT MATCHED THEN INSERT (employee_id, salary) VALUES (employees2.employee_id, 55000.00);
----
CommitSink
└── DataMutation
    ├── target table: [catalog: default] [database: default] [table: salaries2]
    ├── matched update: [condition: employees2.department (#2) = 'HR', update set salary = if(CAST(_predicate (#18446744073709551615) AS Boolean NULL), CAST(salaries2.salary (#4) + 1000.00 AS Decimal(10, 2) NULL), salaries2.salary (#4))]
    ├── matched update: [condition: None, update set salary = if(CAST(_predicate (#18446744073709551615) AS Boolean NULL), CAST(salaries2.salary (#4) + 500.00 AS Decimal(10, 2) NULL), salaries2.salary (#4))]
    ├── unmatched insert: [condition: None, insert into (employee_id,salary) values(employees2.employee_id (#0),55000.00)]
    └── RowFetch
        ├── output columns: [salaries2.employee_id (#3), salaries2._row_id (#5), employees2.employee_id (#0), employees2.employee_name (#1), employees2.department (#2), salaries2.salary (#4)]
        ├── columns to fetch: [salary]
        └── HashJoin
            ├── output columns: [salaries2.employee_id (#3), salaries2._row_id (#5), employees2.employee_id (#0), employees2.employee_name (#1), employees2.department (#2)]
            ├── join type: RIGHT OUTER
            ├── build keys: [employees2.employee_id (#0)]
            ├── probe keys: [salaries2.employee_id (#3)]
            ├── keys is null equal: [false]
            ├── filters: []
            ├── estimated rows: 4.00
            ├── TableScan(Build)
            │   ├── table: default.default.employees2
            │   ├── output columns: [employee_id (#0), employee_name (#1), department (#2)]
            │   ├── read rows: 4
            │   ├── read size: < 1 KiB
            │   ├── partitions total: 1
            │   ├── partitions scanned: 1
            │   ├── pruning stats: [segments: <range pruning: 1 to 1>, blocks: <range pruning: 1 to 1>]
            │   ├── push downs: [filters: [], limit: NONE]
            │   └── estimated rows: 4.00
            └── TableScan(Probe)
                ├── table: default.default.salaries2
                ├── output columns: [employee_id (#3), _row_id (#5)]
                ├── read rows: 6
                ├── read size: < 1 KiB
                ├── partitions total: 2
                ├── partitions scanned: 2
                ├── pruning stats: [segments: <range pruning: 2 to 2>, blocks: <range pruning: 2 to 2>]
                ├── push downs: [filters: [], limit: NONE]
                └── estimated rows: 6.00

query T
explain MERGE INTO salaries2 USING (SELECT * FROM employees2) as employees2 ON salaries2.employee_id = employees2.employee_id WHEN MATCHED AND employees2.department = 'HR' THEN UPDATE SET salaries2.salary = salaries2.salary + 1000.00 WHEN MATCHED THEN UPDATE SET salaries2.salary = salaries2.salary + 500.00 WHEN NOT MATCHED THEN INSERT (employee_id, salary) VALUES (employees2.employee_id, 55000.00);
----
CommitSink
└── DataMutation
    ├── target table: [catalog: default] [database: default] [table: salaries2]
    ├── matched update: [condition: employees2.department (#2) = 'HR', update set salary = if(CAST(_predicate (#18446744073709551615) AS Boolean NULL), CAST(salaries2.salary (#4) + 1000.00 AS Decimal(10, 2) NULL), salaries2.salary (#4))]
    ├── matched update: [condition: None, update set salary = if(CAST(_predicate (#18446744073709551615) AS Boolean NULL), CAST(salaries2.salary (#4) + 500.00 AS Decimal(10, 2) NULL), salaries2.salary (#4))]
    ├── unmatched insert: [condition: None, insert into (employee_id,salary) values(employees2.employee_id (#0),55000.00)]
    └── RowFetch
        ├── output columns: [salaries2.employee_id (#3), salaries2._row_id (#5), employees2.employee_id (#0), employees2.employee_name (#1), employees2.department (#2), salaries2.salary (#4)]
        ├── columns to fetch: [salary]
        └── HashJoin
            ├── output columns: [salaries2.employee_id (#3), salaries2._row_id (#5), employees2.employee_id (#0), employees2.employee_name (#1), employees2.department (#2)]
            ├── join type: RIGHT OUTER
            ├── build keys: [employees2.employee_id (#0)]
            ├── probe keys: [salaries2.employee_id (#3)]
            ├── keys is null equal: [false]
            ├── filters: []
            ├── estimated rows: 4.00
            ├── TableScan(Build)
            │   ├── table: default.default.employees2
            │   ├── output columns: [employee_id (#0), employee_name (#1), department (#2)]
            │   ├── read rows: 4
            │   ├── read size: < 1 KiB
            │   ├── partitions total: 1
            │   ├── partitions scanned: 1
            │   ├── pruning stats: [segments: <range pruning: 1 to 1>, blocks: <range pruning: 1 to 1>]
            │   ├── push downs: [filters: [], limit: NONE]
            │   └── estimated rows: 4.00
            └── TableScan(Probe)
                ├── table: default.default.salaries2
                ├── output columns: [employee_id (#3), _row_id (#5)]
                ├── read rows: 6
                ├── read size: < 1 KiB
                ├── partitions total: 2
                ├── partitions scanned: 2
                ├── pruning stats: [segments: <range pruning: 2 to 2>, blocks: <range pruning: 2 to 2>]
                ├── push downs: [filters: [], limit: NONE]
                └── estimated rows: 6.00

## test update column only optimization
statement ok
drop table if exists column_only_optimization_target;

statement ok
drop table if exists column_only_optimization_source;

statement ok
create table column_only_optimization_target(a int,b string);

statement ok
create table column_only_optimization_source(a int,b string);

statement ok
set join_spilling_memory_ratio = 0;

query T
explain MERGE INTO column_only_optimization_target as t1 using column_only_optimization_source as t2
on t1.a = t2.a when matched then update set t1.b = t2.b when not matched then insert *;
----
CommitSink
└── DataMutation
    ├── target table: [catalog: default] [database: default] [table: column_only_optimization_target]
    ├── matched update: [condition: None, update set b = if(CAST(_predicate (#18446744073709551615) AS Boolean NULL), t2.b (#1), t1.b (#3))]
    ├── unmatched insert: [condition: None, insert into (a,b) values(a (#0),b (#1))]
    └── RowFetch
        ├── output columns: [t2.a (#0), t2.b (#1), t1.a (#2), t1._row_id (#4), t1.b (#3)]
        ├── columns to fetch: [b]
        └── HashJoin
            ├── output columns: [t2.a (#0), t2.b (#1), t1.a (#2), t1._row_id (#4)]
            ├── join type: LEFT OUTER
            ├── build keys: [t1.a (#2)]
            ├── probe keys: [t2.a (#0)]
            ├── keys is null equal: [false]
            ├── filters: []
            ├── estimated rows: 0.00
            ├── TableScan(Build)
            │   ├── table: default.default.column_only_optimization_target
            │   ├── output columns: [a (#2), _row_id (#4)]
            │   ├── read rows: 0
            │   ├── read size: 0
            │   ├── partitions total: 0
            │   ├── partitions scanned: 0
            │   ├── push downs: [filters: [], limit: NONE]
            │   └── estimated rows: 0.00
            └── TableScan(Probe)
                ├── table: default.default.column_only_optimization_source
                ├── output columns: [a (#0), b (#1)]
                ├── read rows: 0
                ├── read size: 0
                ├── partitions total: 0
                ├── partitions scanned: 0
                ├── push downs: [filters: [], limit: NONE]
                └── estimated rows: 0.00

query T
explain MERGE INTO column_only_optimization_target as t1 using column_only_optimization_source as t2
on t1.a = t2.a when matched then update * when not matched then insert *;
----
CommitSink
└── DataMutation
    ├── target table: [catalog: default] [database: default] [table: column_only_optimization_target]
    ├── matched update: [condition: None, update set a = if(CAST(_predicate (#18446744073709551615) AS Boolean NULL), a (#0), t1.a (#2)),b = if(CAST(_predicate (#18446744073709551615) AS Boolean NULL), b (#1), t1.b (#3))]
    ├── unmatched insert: [condition: None, insert into (a,b) values(a (#0),b (#1))]
    └── RowFetch
        ├── output columns: [t2.a (#0), t2.b (#1), t1.a (#2), t1._row_id (#4), t1.b (#3)]
        ├── columns to fetch: [b]
        └── HashJoin
            ├── output columns: [t2.a (#0), t2.b (#1), t1.a (#2), t1._row_id (#4)]
            ├── join type: LEFT OUTER
            ├── build keys: [t1.a (#2)]
            ├── probe keys: [t2.a (#0)]
            ├── keys is null equal: [false]
            ├── filters: []
            ├── estimated rows: 0.00
            ├── TableScan(Build)
            │   ├── table: default.default.column_only_optimization_target
            │   ├── output columns: [a (#2), _row_id (#4)]
            │   ├── read rows: 0
            │   ├── read size: 0
            │   ├── partitions total: 0
            │   ├── partitions scanned: 0
            │   ├── push downs: [filters: [], limit: NONE]
            │   └── estimated rows: 0.00
            └── TableScan(Probe)
                ├── table: default.default.column_only_optimization_source
                ├── output columns: [a (#0), b (#1)]
                ├── read rows: 0
                ├── read size: 0
                ├── partitions total: 0
                ├── partitions scanned: 0
                ├── push downs: [filters: [], limit: NONE]
                └── estimated rows: 0.00

statement ok
set join_spilling_memory_ratio = 60;

query T
explain MERGE INTO column_only_optimization_target as t1 using column_only_optimization_source as t2
on t1.a = t2.a when matched then update set t1.b = 'test' when not matched then insert *;
----
CommitSink
└── DataMutation
    ├── target table: [catalog: default] [database: default] [table: column_only_optimization_target]
    ├── matched update: [condition: None, update set b = if(CAST(_predicate (#18446744073709551615) AS Boolean NULL), 'test', t1.b (#3))]
    ├── unmatched insert: [condition: None, insert into (a,b) values(a (#0),b (#1))]
    └── RowFetch
        ├── output columns: [t2.a (#0), t2.b (#1), t1.a (#2), t1._row_id (#4), t1.b (#3)]
        ├── columns to fetch: [b]
        └── HashJoin
            ├── output columns: [t2.a (#0), t2.b (#1), t1.a (#2), t1._row_id (#4)]
            ├── join type: LEFT OUTER
            ├── build keys: [t1.a (#2)]
            ├── probe keys: [t2.a (#0)]
            ├── keys is null equal: [false]
            ├── filters: []
            ├── estimated rows: 0.00
            ├── TableScan(Build)
            │   ├── table: default.default.column_only_optimization_target
            │   ├── output columns: [a (#2), _row_id (#4)]
            │   ├── read rows: 0
            │   ├── read size: 0
            │   ├── partitions total: 0
            │   ├── partitions scanned: 0
            │   ├── push downs: [filters: [], limit: NONE]
            │   └── estimated rows: 0.00
            └── TableScan(Probe)
                ├── table: default.default.column_only_optimization_source
                ├── output columns: [a (#0), b (#1)]
                ├── read rows: 0
                ├── read size: 0
                ├── partitions total: 0
                ├── partitions scanned: 0
                ├── push downs: [filters: [], limit: NONE]
                └── estimated rows: 0.00

query T
explain MERGE INTO column_only_optimization_target as t1 using column_only_optimization_source as t2
on t1.a = t2.a when matched then update set t1.b = concat(t2.b,'test') when not matched then insert *;
----
CommitSink
└── DataMutation
    ├── target table: [catalog: default] [database: default] [table: column_only_optimization_target]
    ├── matched update: [condition: None, update set b = if(CAST(_predicate (#18446744073709551615) AS Boolean NULL), concat(t2.b (#1), 'test'), t1.b (#3))]
    ├── unmatched insert: [condition: None, insert into (a,b) values(a (#0),b (#1))]
    └── RowFetch
        ├── output columns: [t2.a (#0), t2.b (#1), t1.a (#2), t1._row_id (#4), t1.b (#3)]
        ├── columns to fetch: [b]
        └── HashJoin
            ├── output columns: [t2.a (#0), t2.b (#1), t1.a (#2), t1._row_id (#4)]
            ├── join type: LEFT OUTER
            ├── build keys: [t1.a (#2)]
            ├── probe keys: [t2.a (#0)]
            ├── keys is null equal: [false]
            ├── filters: []
            ├── estimated rows: 0.00
            ├── TableScan(Build)
            │   ├── table: default.default.column_only_optimization_target
            │   ├── output columns: [a (#2), _row_id (#4)]
            │   ├── read rows: 0
            │   ├── read size: 0
            │   ├── partitions total: 0
            │   ├── partitions scanned: 0
            │   ├── push downs: [filters: [], limit: NONE]
            │   └── estimated rows: 0.00
            └── TableScan(Probe)
                ├── table: default.default.column_only_optimization_source
                ├── output columns: [a (#0), b (#1)]
                ├── read rows: 0
                ├── read size: 0
                ├── partitions total: 0
                ├── partitions scanned: 0
                ├── push downs: [filters: [], limit: NONE]
                └── estimated rows: 0.00

statement ok
set enable_experimental_merge_into = 0;

statement ok
drop table employees2;

statement ok
drop table salaries2;
