statement ok
drop table if exists t1 all

statement ok
drop table if exists t2 all

statement ok
settings (ddl_column_type_nullable=0) create OR REPLACE table t1 as select number as a, number as b from numbers(1)

statement ok
settings (ddl_column_type_nullable=0) create OR REPLACE table t2 as select number as a, number as b from numbers(5)

statement error 1005
explain explain select t1.a from t1 where a > 0

statement error 1005
explain explain analyze select t1.a from t1 where a > 0

statement error 1005
explain analyze explain select t1.a from t1 where a > 0

statement error 1005
explain analyze explain analyze select t1.a from t1 where a > 0

query T
explain select t1.a from t1 where a > 0
----
TableScan
├── table: default.default.t1
├── scan id: 0
├── output columns: [a (#0)]
├── read rows: 0
├── read size: 0
├── partitions total: 1
├── partitions scanned: 0
├── pruning stats: [segments: <range pruning: 1 to 0 cost: <slt:ignore>>]
├── push downs: [filters: [t1.a (#0) > 0], limit: NONE]
└── estimated rows: 0.00

query T
explain select * from t1, t2 where (t1.a = t2.a and t1.a > 3) or (t1.a = t2.a and t2.a > 5 and t1.a > 1)
----
Filter
├── output columns: [t2.a (#2), t2.b (#3), t1.b (#1), t1.a (#0)]
├── filters: [t1.a (#0) > 3 or t2.a (#2) > 5 and t1.a (#0) > 1]
├── estimated rows: 0.00
└── HashJoin
    ├── output columns: [t2.a (#2), t2.b (#3), t1.b (#1), t1.a (#0)]
    ├── join type: INNER
    ├── build keys: [t1.a (#0)]
    ├── probe keys: [t2.a (#2)]
    ├── keys is null equal: [false]
    ├── filters: []
    ├── build join filters:
    │   └── filter id:0, build key:t1.a (#0), probe targets:[t2.a (#2)@scan1], filter type:bloom,inlist,min_max
    ├── estimated rows: 0.00
    ├── TableScan(Build)
    │   ├── table: default.default.t1
    │   ├── scan id: 0
    │   ├── output columns: [a (#0), b (#1)]
    │   ├── read rows: 0
    │   ├── read size: 0
    │   ├── partitions total: 1
    │   ├── partitions scanned: 0
    │   ├── pruning stats: [segments: <range pruning: 1 to 0 cost: <slt:ignore>>]
    │   ├── push downs: [filters: [t1.a (#0) > 3 or t1.a (#0) > 1], limit: NONE]
    │   └── estimated rows: 0.00
    └── TableScan(Probe)
        ├── table: default.default.t2
        ├── scan id: 1
        ├── output columns: [a (#2), b (#3)]
        ├── read rows: 5
        ├── read size: < 1 KiB
        ├── partitions total: 1
        ├── partitions scanned: 1
        ├── pruning stats: [segments: <range pruning: 1 to 1 cost: <slt:ignore>>, blocks: <range pruning: 1 to 1 cost: <slt:ignore>>]
        ├── push downs: [filters: [t2.a (#2) > 3 or t2.a (#2) > 1], limit: NONE]
        ├── apply join filters: [#0]
        └── estimated rows: 3.40

query T
explain select * from t1, t2 where (t1.a = t2.a and t1.a > 3) or (t1.a = t2.a)
----
HashJoin
├── output columns: [t2.a (#2), t2.b (#3), t1.b (#1), t1.a (#0)]
├── join type: INNER
├── build keys: [t1.a (#0)]
├── probe keys: [t2.a (#2)]
├── keys is null equal: [false]
├── filters: []
├── build join filters:
│   └── filter id:0, build key:t1.a (#0), probe targets:[t2.a (#2)@scan1], filter type:bloom,inlist,min_max
├── estimated rows: 1.00
├── TableScan(Build)
│   ├── table: default.default.t1
│   ├── scan id: 0
│   ├── output columns: [a (#0), b (#1)]
│   ├── read rows: 1
│   ├── read size: < 1 KiB
│   ├── partitions total: 1
│   ├── partitions scanned: 1
│   ├── pruning stats: [segments: <range pruning: 1 to 1 cost: <slt:ignore>>, blocks: <range pruning: 1 to 1 cost: <slt:ignore>>]
│   ├── push downs: [filters: [], limit: NONE]
│   └── estimated rows: 1.00
└── TableScan(Probe)
    ├── table: default.default.t2
    ├── scan id: 1
    ├── output columns: [a (#2), b (#3)]
    ├── read rows: 5
    ├── read size: < 1 KiB
    ├── partitions total: 1
    ├── partitions scanned: 1
    ├── pruning stats: [segments: <range pruning: 1 to 1 cost: <slt:ignore>>, blocks: <range pruning: 1 to 1 cost: <slt:ignore>>]
    ├── push downs: [filters: [], limit: NONE]
    ├── apply join filters: [#0]
    └── estimated rows: 5.00

query T
explain raw select * from t1, t2 where (t1.a = t2.a and t1.a > 3) or (t1.a = t2.a)
----
EvalScalar
├── scalars: [t1.a (#0) AS (#0), t1.b (#1) AS (#1), t2.a (#2) AS (#2), t2.b (#3) AS (#3)]
└── Filter
    ├── filters: [or(and(eq(t1.a (#0), t2.a (#2)), gt(t1.a (#0), 3)), eq(t1.a (#0), t2.a (#2)))]
    └── Join(Cross)
        ├── build keys: []
        ├── probe keys: []
        ├── other filters: []
        ├── Scan
        │   ├── table: default.t2 (#1)
        │   ├── filters: []
        │   ├── order by: []
        │   └── limit: NONE
        └── Scan
            ├── table: default.t1 (#0)
            ├── filters: []
            ├── order by: []
            └── limit: NONE

query T
explain raw select * from t1 inner join t2 on t1.a = t2.a and t1.b = t2.b and t1.a > 2
----
EvalScalar
├── scalars: [t1.a (#0) AS (#0), t1.b (#1) AS (#1), t2.a (#2) AS (#2), t2.b (#3) AS (#3)]
└── Join(Inner)
    ├── build keys: [t2.a (#2), t2.b (#3)]
    ├── probe keys: [t1.a (#0), t1.b (#1)]
    ├── other filters: []
    ├── Scan
    │   ├── table: default.t2 (#1)
    │   ├── filters: []
    │   ├── order by: []
    │   └── limit: NONE
    └── Filter
        ├── filters: [gt(t1.a (#0), 2)]
        └── Scan
            ├── table: default.t1 (#0)
            ├── filters: []
            ├── order by: []
            └── limit: NONE

query T
explain syntax select 1, 'ab', [1,2,3], (1, 'a')
----
SELECT 1, 'ab', [1, 2, 3], (1, 'a')

query T
explain syntax select a, sum(b) as sum from t1 where a in (1, 2) and b > 0 and b < 100 group by a order by a
----
SELECT a, sum(b) AS sum FROM t1 WHERE a IN(1, 2) AND b > 0 AND b < 100 GROUP BY a ORDER BY a

query T
explain syntax select * from t1 inner join t2 on t1.a = t2.a and t1.b = t2.b and t1.a > 2
----
SELECT * FROM t1 INNER JOIN t2 ON t1.a = t2.a AND t1.b = t2.b AND t1.a > 2

query T
explain syntax delete from t1 where a > 100 and b > 1 and b < 10
----
DELETE FROM t1 WHERE a > 100 AND b > 1 AND b < 10


query T
explain syntax copy into t1 from 's3://mybucket/data.csv' file_format = ( type = CSV field_delimiter = ',' record_delimiter = '\n' skip_header = 1) size_limit=10
----
COPY INTO t1 FROM 's3://mybucket/data.csv' FILE_FORMAT = (field_delimiter = ',', record_delimiter = '\n', skip_header = 1, type = CSV)  SIZE_LIMIT = 10 PURGE = false FORCE = false DISABLE_VARIANT_CHECK = false ON_ERROR = abort RETURN_FAILED_ONLY = false


query T
explain syntax copy into 's3://mybucket/data.csv' from t1 file_format = ( type = CSV field_delimiter = ',' record_delimiter = '\n' skip_header = 1)
----
COPY INTO 's3://mybucket/data.csv' FROM t1 FILE_FORMAT = (field_delimiter = ',', record_delimiter = '\n', skip_header = 1, type = CSV) SINGLE = false MAX_FILE_SIZE = 0 DETAILED_OUTPUT = false INCLUDE_QUERY_ID = true USE_RAW_PATH = false OVERWRITE = false

query T
explain syntax create OR REPLACE table t3(a int64, b uint64, c float64, d string, e array(int32), f tuple(f1 bool, f2 string)) engine=fuse cluster by (a, b, c) comment='test' compression='LZ4'
----
CREATE OR REPLACE TABLE t3 (a Int64, b UInt64, c Float64, d STRING, e ARRAY(Int32), f TUPLE(f1 BOOLEAN, f2 STRING)) ENGINE = FUSE CLUSTER BY LINEAR(a, b, c) comment = 'test' compression = 'LZ4'

query T
explain syntax create view v as select number % 3 as a from numbers(100) where number > 10
----
CREATE VIEW v AS SELECT number % 3 AS a FROM numbers(100) WHERE number > 10

query T
explain syntax select 1, 'ab', [1,2,3] as a, (1, 'a') as t
----
SELECT 1, 'ab', [1, 2, 3] AS a, (1, 'a') AS t

query T
explain syntax select case when a > 1 then 'x' when a < 10 then 'y' else 'z' end from t1
----
SELECT CASE WHEN a > 1 THEN 'x' WHEN a < 10 THEN 'y' ELSE 'z' END FROM t1

query T
explain syntax select a, sum(b) as sum from t1 where a in (1, 2) and b > 0 and b < 100 group by a order by a limit 3
----
SELECT a, sum(b) AS sum FROM t1 WHERE a IN(1, 2) AND b > 0 AND b < 100 GROUP BY a ORDER BY a LIMIT 3

query T
explain syntax select * from t1 inner join t2 on t1.a = t2.a and t1.b = t2.b and t1.a > 2
----
SELECT * FROM t1 INNER JOIN t2 ON t1.a = t2.a AND t1.b = t2.b AND t1.a > 2

query T
explain syntax with cte (a, b) as (select 1, 2 union all select 3, 4) select a, b from cte
----
WITH cte(a, b) AS (SELECT 1, 2 UNION ALL SELECT 3, 4) SELECT a, b FROM cte

query T
explain syntax with cte (a, b) as (values(1,2),(3,4)) select a, b from cte
----
WITH cte(a, b) AS (VALUES(1, 2), (3, 4)) SELECT a, b FROM cte

query T
explain syntax insert into t1 (a, b) values (1, 2),(3, 4)
----
INSERT INTO t1 (a, b) VALUES (1, 2), (3, 4)

query T
explain syntax delete from t1 where a > 100 and b > 1 and b < 10
----
DELETE FROM t1 WHERE a > 100 AND b > 1 AND b < 10


query T
explain syntax copy into t1 from 's3://mybucket/data.csv' file_format = ( type = CSV field_delimiter = ',' record_delimiter = '\n' skip_header = 1) size_limit=10 max_files=10
----
COPY INTO t1 FROM 's3://mybucket/data.csv' FILE_FORMAT = (field_delimiter = ',', record_delimiter = '\n', skip_header = 1, type = CSV)  SIZE_LIMIT = 10 MAX_FILES = 10 PURGE = false FORCE = false DISABLE_VARIANT_CHECK = false ON_ERROR = abort RETURN_FAILED_ONLY = false

query T
explain syntax create database db1 engine=default
----
CREATE DATABASE db1 ENGINE = DEFAULT

query T
explain syntax create OR REPLACE table t3(a int64, b uint64, c float64, d string, e array(int32), f tuple(f1 bool, f2 string)) engine=fuse cluster by (a, b, c) comment='test' compression='LZ4'
----
CREATE OR REPLACE TABLE t3 (a Int64, b UInt64, c Float64, d STRING, e ARRAY(Int32), f TUPLE(f1 BOOLEAN, f2 STRING)) ENGINE = FUSE CLUSTER BY LINEAR(a, b, c) comment = 'test' compression = 'LZ4'

query T
explain syntax create view v as select number % 3 as a from numbers(100) where number > 10
----
CREATE VIEW v AS SELECT number % 3 AS a FROM numbers(100) WHERE number > 10

query T
explain syntax show create table t1
----
SHOW CREATE TABLE t1

query T
explain syntax create user 'test' identified with sha256_password by 'new_password'
----
CREATE USER 'test'@'%' IDENTIFIED WITH sha256_password BY 'new_password'

query T
explain syntax select unknown_table.a + 1 from unknown_table1
----
SELECT unknown_table.a + 1 FROM unknown_table1

query T
explain syntax SELECT * FROM monthly_sales PIVOT(SUM(amount) FOR MONTH IN ('JAN', 'FEB', 'MAR', 'APR')) ORDER BY EMPID
----
SELECT * FROM monthly_sales PIVOT(SUM(amount) FOR MONTH IN ('JAN', 'FEB', 'MAR', 'APR')) ORDER BY EMPID

query T
explain syntax SELECT * FROM monthly_sales_1 UNPIVOT(sales FOR month IN (jan, feb, mar, april)) ORDER BY empid
----
SELECT * FROM monthly_sales_1 UNPIVOT(sales FOR month IN (jan, feb, mar, april)) ORDER BY empid

query T
explain select a from t1 UNION ALL select a from t2
----
UnionAll
├── output columns: [a (#4)]
├── estimated rows: 6.00
├── TableScan
│   ├── table: default.default.t1
│   ├── scan id: 0
│   ├── output columns: [a (#0)]
│   ├── read rows: 1
│   ├── read size: < 1 KiB
│   ├── partitions total: 1
│   ├── partitions scanned: 1
│   ├── pruning stats: [segments: <range pruning: 1 to 1 cost: <slt:ignore>>, blocks: <range pruning: 1 to 1 cost: <slt:ignore>>]
│   ├── push downs: [filters: [], limit: NONE]
│   └── estimated rows: 1.00
└── TableScan
    ├── table: default.default.t2
    ├── scan id: 1
    ├── output columns: [a (#2)]
    ├── read rows: 5
    ├── read size: < 1 KiB
    ├── partitions total: 1
    ├── partitions scanned: 1
    ├── pruning stats: [segments: <range pruning: 1 to 1 cost: <slt:ignore>>, blocks: <range pruning: 1 to 1 cost: <slt:ignore>>]
    ├── push downs: [filters: [], limit: NONE]
    └── estimated rows: 5.00

query T
explain select * from t1,t2 where (t1.a > 1 and t2.a > 2) or (t1.b < 3 and t2.b < 4)
----
Filter
├── output columns: [t2.a (#2), t2.b (#3), t1.a (#0), t1.b (#1)]
├── filters: [t1.a (#0) > 1 and t2.a (#2) > 2 or t1.b (#1) < 3 and t2.b (#3) < 4]
├── estimated rows: 3.52
└── HashJoin
    ├── output columns: [t2.a (#2), t2.b (#3), t1.a (#0), t1.b (#1)]
    ├── join type: CROSS
    ├── build keys: []
    ├── probe keys: []
    ├── keys is null equal: []
    ├── filters: []
    ├── estimated rows: 4.40
    ├── TableScan(Build)
    │   ├── table: default.default.t1
    │   ├── scan id: 0
    │   ├── output columns: [a (#0), b (#1)]
    │   ├── read rows: 1
    │   ├── read size: < 1 KiB
    │   ├── partitions total: 1
    │   ├── partitions scanned: 1
    │   ├── pruning stats: [segments: <range pruning: 1 to 1 cost: <slt:ignore>>, blocks: <range pruning: 1 to 1 cost: <slt:ignore>>]
    │   ├── push downs: [filters: [t1.a (#0) > 1 or t1.b (#1) < 3], limit: NONE]
    │   └── estimated rows: 1.00
    └── TableScan(Probe)
        ├── table: default.default.t2
        ├── scan id: 1
        ├── output columns: [a (#2), b (#3)]
        ├── read rows: 5
        ├── read size: < 1 KiB
        ├── partitions total: 1
        ├── partitions scanned: 1
        ├── pruning stats: [segments: <range pruning: 1 to 1 cost: <slt:ignore>>, blocks: <range pruning: 1 to 1 cost: <slt:ignore>>]
        ├── push downs: [filters: [t2.a (#2) > 2 or t2.b (#3) < 4], limit: NONE]
        └── estimated rows: 4.40

query T
explain select * from t1,t2 where (t1.a > 1 and t2.a > 2) or (t1.b < 3 and t2.b < 4) or t1.a = 2
----
Filter
├── output columns: [t2.a (#2), t2.b (#3), t1.a (#0), t1.b (#1)]
├── filters: [t1.a (#0) > 1 and t2.a (#2) > 2 or t1.b (#1) < 3 and t2.b (#3) < 4 or t1.a (#0) = 2]
├── estimated rows: 4.00
└── HashJoin
    ├── output columns: [t2.a (#2), t2.b (#3), t1.a (#0), t1.b (#1)]
    ├── join type: CROSS
    ├── build keys: []
    ├── probe keys: []
    ├── keys is null equal: []
    ├── filters: []
    ├── estimated rows: 5.00
    ├── TableScan(Build)
    │   ├── table: default.default.t1
    │   ├── scan id: 0
    │   ├── output columns: [a (#0), b (#1)]
    │   ├── read rows: 1
    │   ├── read size: < 1 KiB
    │   ├── partitions total: 1
    │   ├── partitions scanned: 1
    │   ├── pruning stats: [segments: <range pruning: 1 to 1 cost: <slt:ignore>>, blocks: <range pruning: 1 to 1 cost: <slt:ignore>, bloom pruning: 1 to 1 cost: <slt:ignore>>]
    │   ├── push downs: [filters: [t1.a (#0) > 1 or t1.b (#1) < 3 or t1.a (#0) = 2], limit: NONE]
    │   └── estimated rows: 1.00
    └── TableScan(Probe)
        ├── table: default.default.t2
        ├── scan id: 1
        ├── output columns: [a (#2), b (#3)]
        ├── read rows: 5
        ├── read size: < 1 KiB
        ├── partitions total: 1
        ├── partitions scanned: 1
        ├── pruning stats: [segments: <range pruning: 1 to 1 cost: <slt:ignore>>, blocks: <range pruning: 1 to 1 cost: <slt:ignore>>]
        ├── push downs: [filters: [], limit: NONE]
        └── estimated rows: 5.00

statement ok
drop table if exists t3

statement ok
settings (ddl_column_type_nullable=0) create OR REPLACE table t3 as select number as a, number as b from numbers(10)

query T
explain select * from t1,t2, t3 where (t1.a > 1 and t2.a > 2) or (t1.b < 3 and t2.b < 4) or t3.a = 2
----
HashJoin
├── output columns: [t3.a (#4), t3.b (#5), t2.a (#2), t2.b (#3), t1.a (#0), t1.b (#1)]
├── join type: INNER
├── build keys: []
├── probe keys: []
├── keys is null equal: []
├── filters: [t1.a (#0) > 1 and t2.a (#2) > 2 or t1.b (#1) < 3 and t2.b (#3) < 4 or t3.a (#4) = 2]
├── estimated rows: 50.00
├── HashJoin(Build)
│   ├── output columns: [t2.a (#2), t2.b (#3), t1.a (#0), t1.b (#1)]
│   ├── join type: CROSS
│   ├── build keys: []
│   ├── probe keys: []
│   ├── keys is null equal: []
│   ├── filters: []
│   ├── estimated rows: 5.00
│   ├── TableScan(Build)
│   │   ├── table: default.default.t1
│   │   ├── scan id: 0
│   │   ├── output columns: [a (#0), b (#1)]
│   │   ├── read rows: 1
│   │   ├── read size: < 1 KiB
│   │   ├── partitions total: 1
│   │   ├── partitions scanned: 1
│   │   ├── pruning stats: [segments: <range pruning: 1 to 1 cost: <slt:ignore>>, blocks: <range pruning: 1 to 1 cost: <slt:ignore>>]
│   │   ├── push downs: [filters: [], limit: NONE]
│   │   └── estimated rows: 1.00
│   └── TableScan(Probe)
│       ├── table: default.default.t2
│       ├── scan id: 1
│       ├── output columns: [a (#2), b (#3)]
│       ├── read rows: 5
│       ├── read size: < 1 KiB
│       ├── partitions total: 1
│       ├── partitions scanned: 1
│       ├── pruning stats: [segments: <range pruning: 1 to 1 cost: <slt:ignore>>, blocks: <range pruning: 1 to 1 cost: <slt:ignore>>]
│       ├── push downs: [filters: [], limit: NONE]
│       └── estimated rows: 5.00
└── TableScan(Probe)
    ├── table: default.default.t3
    ├── scan id: 2
    ├── output columns: [a (#4), b (#5)]
    ├── read rows: 10
    ├── read size: < 1 KiB
    ├── partitions total: 1
    ├── partitions scanned: 1
    ├── pruning stats: [segments: <range pruning: 1 to 1 cost: <slt:ignore>>, blocks: <range pruning: 1 to 1 cost: <slt:ignore>>]
    ├── push downs: [filters: [], limit: NONE]
    └── estimated rows: 10.00

query T
explain select * from t1,t2, t3 where ((t1.a > 1 and t2.a > 2) or (t1.b < 3 and t2.b < 4)) and t3.a > 1
----
HashJoin
├── output columns: [t3.a (#4), t3.b (#5), t2.a (#2), t2.b (#3), t1.a (#0), t1.b (#1)]
├── join type: CROSS
├── build keys: []
├── probe keys: []
├── keys is null equal: []
├── filters: []
├── estimated rows: 28.16
├── Filter(Build)
│   ├── output columns: [t2.a (#2), t2.b (#3), t1.a (#0), t1.b (#1)]
│   ├── filters: [t1.a (#0) > 1 and t2.a (#2) > 2 or t1.b (#1) < 3 and t2.b (#3) < 4]
│   ├── estimated rows: 3.52
│   └── HashJoin
│       ├── output columns: [t2.a (#2), t2.b (#3), t1.a (#0), t1.b (#1)]
│       ├── join type: CROSS
│       ├── build keys: []
│       ├── probe keys: []
│       ├── keys is null equal: []
│       ├── filters: []
│       ├── estimated rows: 4.40
│       ├── TableScan(Build)
│       │   ├── table: default.default.t1
│       │   ├── scan id: 0
│       │   ├── output columns: [a (#0), b (#1)]
│       │   ├── read rows: 1
│       │   ├── read size: < 1 KiB
│       │   ├── partitions total: 1
│       │   ├── partitions scanned: 1
│       │   ├── pruning stats: [segments: <range pruning: 1 to 1 cost: <slt:ignore>>, blocks: <range pruning: 1 to 1 cost: <slt:ignore>>]
│       │   ├── push downs: [filters: [t1.a (#0) > 1 or t1.b (#1) < 3], limit: NONE]
│       │   └── estimated rows: 1.00
│       └── TableScan(Probe)
│           ├── table: default.default.t2
│           ├── scan id: 1
│           ├── output columns: [a (#2), b (#3)]
│           ├── read rows: 5
│           ├── read size: < 1 KiB
│           ├── partitions total: 1
│           ├── partitions scanned: 1
│           ├── pruning stats: [segments: <range pruning: 1 to 1 cost: <slt:ignore>>, blocks: <range pruning: 1 to 1 cost: <slt:ignore>>]
│           ├── push downs: [filters: [t2.a (#2) > 2 or t2.b (#3) < 4], limit: NONE]
│           └── estimated rows: 4.40
└── TableScan(Probe)
    ├── table: default.default.t3
    ├── scan id: 2
    ├── output columns: [a (#4), b (#5)]
    ├── read rows: 10
    ├── read size: < 1 KiB
    ├── partitions total: 1
    ├── partitions scanned: 1
    ├── pruning stats: [segments: <range pruning: 1 to 1 cost: <slt:ignore>>, blocks: <range pruning: 1 to 1 cost: <slt:ignore>>]
    ├── push downs: [filters: [t3.a (#4) > 1], limit: NONE]
    └── estimated rows: 8.00

query T
explain select * from t1,t2 where ((t1.a > 1 or t1.b < 2) and t2.a > 2) or (t1.b < 3 and t2.b < 4) order by 1 desc limit 3
----
Limit
├── output columns: [t2.a (#2), t2.b (#3), t1.a (#0), t1.b (#1)]
├── limit: 3
├── offset: 0
├── estimated rows: 3.00
└── Sort(Single)
    ├── output columns: [t2.a (#2), t2.b (#3), t1.a (#0), t1.b (#1)]
    ├── sort keys: [a DESC NULLS LAST]
    ├── estimated rows: 3.85
    └── Filter
        ├── output columns: [t2.a (#2), t2.b (#3), t1.a (#0), t1.b (#1)]
        ├── filters: [(t1.a (#0) > 1 or t1.b (#1) < 2) and t2.a (#2) > 2 or t1.b (#1) < 3 and t2.b (#3) < 4]
        ├── estimated rows: 3.85
        └── HashJoin
            ├── output columns: [t2.a (#2), t2.b (#3), t1.a (#0), t1.b (#1)]
            ├── join type: CROSS
            ├── build keys: []
            ├── probe keys: []
            ├── keys is null equal: []
            ├── filters: []
            ├── estimated rows: 4.40
            ├── TableScan(Build)
            │   ├── table: default.default.t1
            │   ├── scan id: 0
            │   ├── output columns: [a (#0), b (#1)]
            │   ├── read rows: 1
            │   ├── read size: < 1 KiB
            │   ├── partitions total: 1
            │   ├── partitions scanned: 1
            │   ├── pruning stats: [segments: <range pruning: 1 to 1 cost: <slt:ignore>>, blocks: <range pruning: 1 to 1 cost: <slt:ignore>>]
            │   ├── push downs: [filters: [t1.a (#0) > 1 or t1.b (#1) < 2 or t1.b (#1) < 3], limit: NONE]
            │   └── estimated rows: 1.00
            └── TableScan(Probe)
                ├── table: default.default.t2
                ├── scan id: 1
                ├── output columns: [a (#2), b (#3)]
                ├── read rows: 5
                ├── read size: < 1 KiB
                ├── partitions total: 1
                ├── partitions scanned: 1
                ├── pruning stats: [segments: <range pruning: 1 to 1 cost: <slt:ignore>>, blocks: <range pruning: 1 to 1 cost: <slt:ignore>>]
                ├── push downs: [filters: [t2.a (#2) > 2 or t2.b (#3) < 4], limit: NONE]
                └── estimated rows: 4.40

query T
explain select * from t1,t2 where (t1.a > 1 or t1.b < 2) and (t1.a > 1 or t1.b < 2)
----
HashJoin
├── output columns: [t2.a (#2), t2.b (#3), t1.a (#0), t1.b (#1)]
├── join type: CROSS
├── build keys: []
├── probe keys: []
├── keys is null equal: []
├── filters: []
├── estimated rows: 5.00
├── TableScan(Build)
│   ├── table: default.default.t1
│   ├── scan id: 0
│   ├── output columns: [a (#0), b (#1)]
│   ├── read rows: 1
│   ├── read size: < 1 KiB
│   ├── partitions total: 1
│   ├── partitions scanned: 1
│   ├── pruning stats: [segments: <range pruning: 1 to 1 cost: <slt:ignore>>, blocks: <range pruning: 1 to 1 cost: <slt:ignore>>]
│   ├── push downs: [filters: [t1.a (#0) > 1 or t1.b (#1) < 2], limit: NONE]
│   └── estimated rows: 1.00
└── TableScan(Probe)
    ├── table: default.default.t2
    ├── scan id: 1
    ├── output columns: [a (#2), b (#3)]
    ├── read rows: 5
    ├── read size: < 1 KiB
    ├── partitions total: 1
    ├── partitions scanned: 1
    ├── pruning stats: [segments: <range pruning: 1 to 1 cost: <slt:ignore>>, blocks: <range pruning: 1 to 1 cost: <slt:ignore>>]
    ├── push downs: [filters: [], limit: NONE]
    └── estimated rows: 5.00

query T
explain select count(distinct a) from t1;
----
AggregateFinal
├── output columns: [count(_1) (#2)]
├── group by: []
├── aggregate functions: [count()]
├── estimated rows: 1.00
└── AggregatePartial
    ├── group by: []
    ├── aggregate functions: [count()]
    ├── estimated rows: 1.00
    └── AggregateFinal
        ├── output columns: [t1.a (#0)]
        ├── group by: [a]
        ├── aggregate functions: []
        ├── estimated rows: 1.00
        └── AggregatePartial
            ├── group by: [a]
            ├── aggregate functions: []
            ├── estimated rows: 1.00
            └── TableScan
                ├── table: default.default.t1
                ├── scan id: 0
                ├── output columns: [a (#0)]
                ├── read rows: 1
                ├── read size: < 1 KiB
                ├── partitions total: 1
                ├── partitions scanned: 1
                ├── pruning stats: [segments: <range pruning: 1 to 1 cost: <slt:ignore>>, blocks: <range pruning: 1 to 1 cost: <slt:ignore>>]
                ├── push downs: [filters: [], limit: NONE]
                └── estimated rows: 1.00

query T
explain select count_distinct(a) from t1;
----
AggregateFinal
├── output columns: [count(_1) (#2)]
├── group by: []
├── aggregate functions: [count()]
├── estimated rows: 1.00
└── AggregatePartial
    ├── group by: []
    ├── aggregate functions: [count()]
    ├── estimated rows: 1.00
    └── AggregateFinal
        ├── output columns: [t1.a (#0)]
        ├── group by: [a]
        ├── aggregate functions: []
        ├── estimated rows: 1.00
        └── AggregatePartial
            ├── group by: [a]
            ├── aggregate functions: []
            ├── estimated rows: 1.00
            └── TableScan
                ├── table: default.default.t1
                ├── scan id: 0
                ├── output columns: [a (#0)]
                ├── read rows: 1
                ├── read size: < 1 KiB
                ├── partitions total: 1
                ├── partitions scanned: 1
                ├── pruning stats: [segments: <range pruning: 1 to 1 cost: <slt:ignore>>, blocks: <range pruning: 1 to 1 cost: <slt:ignore>>]
                ├── push downs: [filters: [], limit: NONE]
                └── estimated rows: 1.00

query T
explain select * from (values(1, 'a'),(2, 'b')) t(c1,c2)
----
ConstantTableScan
├── output columns: [c1 (#0), c2 (#1)]
├── column 0: [1, 2]
└── column 1: ['a', 'b']

statement ok
drop table t1

statement ok
drop table t2

query T
explain syntax select * from read_parquet('p1', 'p2', 'p3');
----
SELECT * FROM read_parquet('p1', 'p2', 'p3')

query T
explain syntax select * from read_parquet(prune_page=>true, refresh_meta_cache=>true);
----
SELECT * FROM read_parquet(prune_page=>TRUE,refresh_meta_cache=>TRUE)

query T
explain syntax select * from read_parquet('p1', 'p2', 'p3', prune_page=>true, refresh_meta_cache=>true);
----
SELECT * FROM read_parquet('p1', 'p2', 'p3',prune_page=>TRUE,refresh_meta_cache=>TRUE)

query T
explain syntax select * from read_parquet('p1', 'p2', 'p3', prune_page=>true, refresh_meta_cache=>true);
----
SELECT * FROM read_parquet('p1', 'p2', 'p3',prune_page=>TRUE,refresh_meta_cache=>TRUE)

statement ok
drop table if exists t4

statement ok
create OR REPLACE table t4(a int, b string);

query T
explain select * from t4 where a = 1 and try_cast(get(try_parse_json(b),'bb') as varchar) = 'xx';
----
TableScan
├── table: default.default.t4
├── scan id: 0
├── output columns: [a (#0), b (#1)]
├── read rows: 0
├── read size: 0
├── partitions total: 0
├── partitions scanned: 0
├── push downs: [filters: [t4.a (#0) = 1 and TRY_CAST(get(try_parse_json(t4.b (#1)), 'bb') AS String NULL) = 'xx'], limit: NONE]
└── estimated rows: 0.00

statement ok
drop view if exists v4

statement ok
create view v4 as select a as a, try_cast(get(try_parse_json(b), 'bb') as varchar) as b from t4;

query T
explain select * from v4 where b = 'xx';
----
EvalScalar
├── output columns: [t4.a (#0), b (#2)]
├── expressions: [TRY_CAST(get(try_parse_json(t4.b (#1)), 'bb') AS String NULL)]
├── estimated rows: 0.00
└── TableScan
    ├── table: default.default.t4
    ├── scan id: 0
    ├── output columns: [a (#0), b (#1)]
    ├── read rows: 0
    ├── read size: 0
    ├── partitions total: 0
    ├── partitions scanned: 0
    ├── push downs: [filters: [is_true(TRY_CAST(get(try_parse_json(t4.b (#1)), 'bb') AS String NULL) = 'xx')], limit: NONE]
    └── estimated rows: 0.00

query T
explain select * from v4 where a > 100;
----
EvalScalar
├── output columns: [t4.a (#0), b (#2)]
├── expressions: [TRY_CAST(get(try_parse_json(t4.b (#1)), 'bb') AS String NULL)]
├── estimated rows: 0.00
└── TableScan
    ├── table: default.default.t4
    ├── scan id: 0
    ├── output columns: [a (#0), b (#1)]
    ├── read rows: 0
    ├── read size: 0
    ├── partitions total: 0
    ├── partitions scanned: 0
    ├── push downs: [filters: [is_true(t4.a (#0) > 100)], limit: NONE]
    └── estimated rows: 0.00

statement ok
drop table if exists a

statement ok
drop table if exists b

statement ok
create OR REPLACE table a(id int, c1 INT NULL)

statement ok
create OR REPLACE table b(id int, c1 INT NULL)

statement ok
insert into a values(1, 1683648000)

statement ok
insert into b values(1, 1683648000)

statement ok
insert into b values(2, 1683648000)

# left join to inner join
query T
explain select * from a left join b on a.id = b.id where a.c1 between 1683648000 and 1683734400 and b.c1 between 1683648000 and 1683734400 limit 1;
----
Limit
├── output columns: [b.id (#2), b.c1 (#3), a.c1 (#1), a.id (#0)]
├── limit: 1
├── offset: 0
├── estimated rows: 1.00
└── HashJoin
    ├── output columns: [b.id (#2), b.c1 (#3), a.c1 (#1), a.id (#0)]
    ├── join type: INNER
    ├── build keys: [a.id (#0)]
    ├── probe keys: [b.id (#2)]
    ├── keys is null equal: [false]
    ├── filters: []
    ├── build join filters:
    │   └── filter id:0, build key:a.id (#0), probe targets:[b.id (#2)@scan1], filter type:bloom,inlist,min_max
    ├── estimated rows: 1.00
    ├── TableScan(Build)
    │   ├── table: default.default.a
    │   ├── scan id: 0
    │   ├── output columns: [id (#0), c1 (#1)]
    │   ├── read rows: 1
    │   ├── read size: < 1 KiB
    │   ├── partitions total: 1
    │   ├── partitions scanned: 1
    │   ├── pruning stats: [segments: <range pruning: 1 to 1 cost: <slt:ignore>>, blocks: <range pruning: 1 to 1 cost: <slt:ignore>>]
    │   ├── push downs: [filters: [a.c1 (#1) >= 1683648000 and a.c1 (#1) <= 1683734400], limit: NONE]
    │   └── estimated rows: 1.00
    └── TableScan(Probe)
        ├── table: default.default.b
        ├── scan id: 1
        ├── output columns: [id (#2), c1 (#3)]
        ├── read rows: 2
        ├── read size: < 1 KiB
        ├── partitions total: 2
        ├── partitions scanned: 2
        ├── pruning stats: [segments: <range pruning: 2 to 2 cost: <slt:ignore>>, blocks: <range pruning: 2 to 2 cost: <slt:ignore>>]
        ├── push downs: [filters: [b.c1 (#3) >= 1683648000 and b.c1 (#3) <= 1683734400], limit: NONE]
        ├── apply join filters: [#0]
        └── estimated rows: 2.00

statement ok
drop table a;

statement ok
drop table b;

# https://github.com/datafuselabs/databend/pull/12026
query T
explain select number, pt, register_at from (select a.number, pt,register_at from ( select number,  to_yyyymmdd(to_timestamp(number))   as pt
from numbers(10) where number > 5
) a join ( select number , to_yyyymmdd(to_timestamp(number)) as  register_at from numbers(10) where number > 5
) b on  a.number=b.number order by a.number) where pt = register_at;
----
Sort(Single)
├── output columns: [numbers.number (#0), pt (#1), register_at (#3)]
├── sort keys: [number ASC NULLS LAST]
├── estimated rows: 25.00
└── HashJoin
    ├── output columns: [numbers.number (#0), pt (#1), register_at (#3)]
    ├── join type: INNER
    ├── build keys: [b.register_at (#3), numbers.number (#2)]
    ├── probe keys: [a.pt (#1), a.number (#0)]
    ├── keys is null equal: [false, false]
    ├── filters: []
    ├── build join filters:
    │   └── filter id:0, build key:numbers.number (#2), probe targets:[a.number (#0)@scan0], filter type:bloom,inlist,min_max
    ├── estimated rows: 25.00
    ├── EvalScalar(Build)
    │   ├── output columns: [numbers.number (#2), register_at (#3)]
    │   ├── expressions: [to_yyyymmdd(CAST(numbers.number (#2) AS Timestamp))]
    │   ├── estimated rows: 5.00
    │   └── Filter
    │       ├── output columns: [numbers.number (#2)]
    │       ├── filters: [numbers.number (#2) > 5]
    │       ├── estimated rows: 5.00
    │       └── TableScan
    │           ├── table: default.system.numbers
    │           ├── scan id: 1
    │           ├── output columns: [number (#2)]
    │           ├── read rows: 10
    │           ├── read size: < 1 KiB
    │           ├── partitions total: 1
    │           ├── partitions scanned: 1
    │           ├── push downs: [filters: [numbers.number (#2) > 5], limit: NONE]
    │           └── estimated rows: 10.00
    └── EvalScalar(Probe)
        ├── output columns: [numbers.number (#0), pt (#1)]
        ├── expressions: [to_yyyymmdd(CAST(numbers.number (#0) AS Timestamp))]
        ├── estimated rows: 5.00
        └── Filter
            ├── output columns: [numbers.number (#0)]
            ├── filters: [numbers.number (#0) > 5]
            ├── estimated rows: 5.00
            └── TableScan
                ├── table: default.system.numbers
                ├── scan id: 0
                ├── output columns: [number (#0)]
                ├── read rows: 10
                ├── read size: < 1 KiB
                ├── partitions total: 1
                ├── partitions scanned: 1
                ├── push downs: [filters: [numbers.number (#0) > 5], limit: NONE]
                ├── apply join filters: [#0]
                └── estimated rows: 10.00

statement ok
create OR REPLACE table a(id int, c1 INT NULL)

statement ok
create OR REPLACE table b(id int, c1 INT NULL)

statement ok
insert into a values (1, 2), (2, 4), (3, 6)

statement ok
insert into b values (1, 5), (4, 8)

# LEFT SINGLE JOIN
query T
explain select * from a where a.id = (select id from b where a.id = b.id);
----
HashJoin
├── output columns: [a.id (#0), a.c1 (#1)]
├── join type: INNER
├── build keys: [scalar_subquery_2 (#2), id (#2)]
├── probe keys: [a.id (#0), a.id (#0)]
├── keys is null equal: [false, false]
├── filters: []
├── build join filters:
│   ├── filter id:0, build key:scalar_subquery_2 (#2), probe targets:[a.id (#0)@scan0], filter type:bloom,inlist,min_max
│   └── filter id:1, build key:id (#2), probe targets:[a.id (#0)@scan0], filter type:bloom,inlist,min_max
├── estimated rows: 0.40
├── TableScan(Build)
│   ├── table: default.default.b
│   ├── scan id: 1
│   ├── output columns: [id (#2)]
│   ├── read rows: 2
│   ├── read size: < 1 KiB
│   ├── partitions total: 1
│   ├── partitions scanned: 1
│   ├── pruning stats: [segments: <range pruning: 1 to 1 cost: <slt:ignore>>, blocks: <range pruning: 1 to 1 cost: <slt:ignore>>]
│   ├── push downs: [filters: [is_true(b.id (#2) = b.id (#2))], limit: NONE]
│   └── estimated rows: 0.40
└── TableScan(Probe)
    ├── table: default.default.a
    ├── scan id: 0
    ├── output columns: [id (#0), c1 (#1)]
    ├── read rows: 3
    ├── read size: < 1 KiB
    ├── partitions total: 1
    ├── partitions scanned: 1
    ├── pruning stats: [segments: <range pruning: 1 to 1 cost: <slt:ignore>>, blocks: <range pruning: 1 to 1 cost: <slt:ignore>>]
    ├── push downs: [filters: [], limit: NONE]
    ├── apply join filters: [#0, #1]
    └── estimated rows: 3.00

statement ok
drop table a;

statement ok
drop table b;

statement ok
create or replace table t1(a int, b int);

statement ok
insert into t1 values(1, 2), (2, 3), (300, 4);

query T
explain settings(inlist_to_join_threshold=5) select * from t1 where a in (0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 3000);
----
HashJoin
├── output columns: [t1.a (#0), t1.b (#1)]
├── join type: INNER
├── build keys: [t1.a (#0)]
├── probe keys: [CAST(CAST(subquery_2 (#2) AS UInt16 NULL) AS Int32 NULL)]
├── keys is null equal: [false]
├── filters: []
├── estimated rows: 2.20
├── TableScan(Build)
│   ├── table: default.default.t1
│   ├── scan id: 0
│   ├── output columns: [a (#0), b (#1)]
│   ├── read rows: 3
│   ├── read size: < 1 KiB
│   ├── partitions total: 1
│   ├── partitions scanned: 1
│   ├── pruning stats: [segments: <range pruning: 1 to 1 cost: <slt:ignore>>, blocks: <range pruning: 1 to 1 cost: <slt:ignore>>]
│   ├── push downs: [filters: [], limit: NONE]
│   └── estimated rows: 3.00
└── AggregateFinal(Probe)
    ├── output columns: [col0 (#2)]
    ├── group by: [col0]
    ├── aggregate functions: []
    ├── estimated rows: 22.00
    └── AggregatePartial
        ├── group by: [col0]
        ├── aggregate functions: []
        ├── estimated rows: 22.00
        └── ConstantTableScan
            ├── output columns: [col0 (#2)]
            └── column 0: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 3000]

query T
explain settings(inlist_to_join_threshold=5) select * from t1 where a not in (0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 3000);
----
Filter
├── output columns: [t1.a (#0), t1.b (#1)]
├── filters: [is_true(NOT 3 (#3))]
├── estimated rows: 1.50
└── HashJoin
    ├── output columns: [t1.a (#0), t1.b (#1), marker (#3)]
    ├── join type: LEFT MARK
    ├── build keys: [t1.a (#0)]
    ├── probe keys: [CAST(CAST(subquery_2 (#2) AS UInt16 NULL) AS Int32 NULL)]
    ├── keys is null equal: [true]
    ├── filters: []
    ├── estimated rows: 3.00
    ├── TableScan(Build)
    │   ├── table: default.default.t1
    │   ├── scan id: 0
    │   ├── output columns: [a (#0), b (#1)]
    │   ├── read rows: 3
    │   ├── read size: < 1 KiB
    │   ├── partitions total: 1
    │   ├── partitions scanned: 1
    │   ├── pruning stats: [segments: <range pruning: 1 to 1 cost: <slt:ignore>>, blocks: <range pruning: 1 to 1 cost: <slt:ignore>>]
    │   ├── push downs: [filters: [], limit: NONE]
    │   └── estimated rows: 3.00
    └── AggregateFinal(Probe)
        ├── output columns: [col0 (#2)]
        ├── group by: [col0]
        ├── aggregate functions: []
        ├── estimated rows: 22.00
        └── AggregatePartial
            ├── group by: [col0]
            ├── aggregate functions: []
            ├── estimated rows: 22.00
            └── ConstantTableScan
                ├── output columns: [col0 (#2)]
                └── column 0: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 3000]

statement ok
CREATE OR REPLACE TABLE t1(i int, j int);

statement ok
CREATE OR REPLACE TABLE t2(k int, l int);

statement ok
INSERT INTO t1 VALUES (1, 2), (2, 3), (3, 4);

statement ok
INSERT INTO t2 VALUES (1, 10), (2, 20);

query T
EXPLAIN SELECT * FROM t1 LEFT OUTER JOIN t2 ON TRUE AND t1.i = t2.k AND FALSE order by i, j;
----
Sort(Single)
├── output columns: [t1.i (#0), t1.j (#1), t2.k (#2), t2.l (#3)]
├── sort keys: [i ASC NULLS LAST, j ASC NULLS LAST]
├── estimated rows: 3.00
└── HashJoin
    ├── output columns: [t1.i (#0), t1.j (#1), t2.k (#2), t2.l (#3)]
    ├── join type: LEFT OUTER
    ├── build keys: [t2.k (#2)]
    ├── probe keys: [t1.i (#0)]
    ├── keys is null equal: [false]
    ├── filters: []
    ├── estimated rows: 3.00
    ├── EmptyResultScan(Build)
    └── TableScan(Probe)
        ├── table: default.default.t1
        ├── scan id: 0
        ├── output columns: [i (#0), j (#1)]
        ├── read rows: 3
        ├── read size: < 1 KiB
        ├── partitions total: 1
        ├── partitions scanned: 1
        ├── pruning stats: [segments: <range pruning: 1 to 1 cost: <slt:ignore>>, blocks: <range pruning: 1 to 1 cost: <slt:ignore>>]
        ├── push downs: [filters: [], limit: NONE]
        └── estimated rows: 3.00

query T
EXPLAIN optimized SELECT * FROM t1 LEFT OUTER JOIN t2 ON TRUE AND t1.i = t2.k AND FALSE order by i, j;
----
Sort
├── sort keys: [t1.i (#0) ASC NULLS LAST, t1.j (#1) ASC NULLS LAST]
├── limit: [NONE]
└── Join(Left)
    ├── build keys: [t2.k (#2)]
    ├── probe keys: [t1.i (#0)]
    ├── other filters: []
    ├── EmptyResultScan
    └── Scan
        ├── table: default.t1 (#0)
        ├── filters: []
        ├── order by: []
        └── limit: NONE


statement ok
drop table if exists t3;

statement ok
CREATE OR REPLACE TABLE t3(a int, b map(string, string) null, c map(string, variant) null);

statement ok
INSERT INTO t3 VALUES (1, {'k1':'a', 'k2':'b'}, {'k1':'"a"', 'k2':'100'}), (2, null, null), (3, {'k3':'z'}, {'k3':'"z"'});

statement ok
INSERT INTO t3 VALUES (4, {'k1':'a', 'k2':'m'}, {'k1':'"a"', 'k2':'"m"'}), (5, null, null), (6, {'k3':'z'}, {'k3':'"v"'});

query T
EXPLAIN SELECT * FROM t3 WHERE b['k2'] = 'm';
----
TableScan
├── table: default.default.t3
├── scan id: 0
├── output columns: [a (#0), b (#1), c (#2)]
├── read rows: 3
├── read size: < 1 KiB
├── partitions total: 2
├── partitions scanned: 1
├── pruning stats: [segments: <range pruning: 2 to 2 cost: <slt:ignore>>, blocks: <range pruning: 2 to 2 cost: <slt:ignore>, bloom pruning: 2 to 1 cost: <slt:ignore>>]
├── push downs: [filters: [is_true(get(t3.b (#1), 'k2') = 'm')], limit: NONE]
└── estimated rows: 1.20

query T
EXPLAIN SELECT * FROM t3 WHERE c['k3'] = 'v';
----
TableScan
├── table: default.default.t3
├── scan id: 0
├── output columns: [a (#0), b (#1), c (#2)]
├── read rows: 3
├── read size: < 1 KiB
├── partitions total: 2
├── partitions scanned: 1
├── pruning stats: [segments: <range pruning: 2 to 2 cost: <slt:ignore>>, blocks: <range pruning: 2 to 2 cost: <slt:ignore>, bloom pruning: 2 to 1 cost: <slt:ignore>>]
├── push downs: [filters: [is_true(get(t3.c (#2), 'k3') = '"v"')], limit: NONE]
└── estimated rows: 1.20

query T
EXPLAIN SELECT * FROM t3 WHERE c['k2'] = 100;
----
TableScan
├── table: default.default.t3
├── scan id: 0
├── output columns: [a (#0), b (#1), c (#2)]
├── read rows: 6
├── read size: < 1 KiB
├── partitions total: 2
├── partitions scanned: 2
├── pruning stats: [segments: <range pruning: 2 to 2 cost: <slt:ignore>>, blocks: <range pruning: 2 to 2 cost: <slt:ignore>>]
├── push downs: [filters: [is_true(TRY_CAST(get(t3.c (#2), 'k2') AS UInt8 NULL) = 100)], limit: NONE]
└── estimated rows: 1.20

statement ok
drop table t1;

statement ok
drop table t2;

statement ok
drop table t3;

statement ok
CREATE OR REPLACE TABLE customers AS SELECT
  number % 100 AS customer_id,
  concat('Customer ', to_string(number % 100)) AS customer_name,
  CASE WHEN (rand() * 10000)::int % 3 = 0 THEN 'Small'
       WHEN (rand() * 10000 % 3)::int = 1 THEN 'Medium'
       ELSE 'Large'
  END AS segment,
  date_add('year', floor(rand() * 100 % 5)::int, '2021-01-01') AS create_timestamp,
  (rand() * 100)::int % 2 = 0 AS active
FROM numbers(100);


statement ok
CREATE OR REPLACE TABLE products AS SELECT
  number % 10 AS product_id,
  concat('Product ', to_string(number % 10)) AS product_name,
  (rand() * 10000 % 2000 * 0.01)::decimal(10, 2) AS price,
  CASE WHEN (rand() * 100)::int % 4 = 0 THEN 'Electronics'
       WHEN (rand() * 100 % 4)::int = 1 THEN 'Clothing'
       WHEN (rand() * 1000 % 4)::int = 2 THEN 'Grocery'
       ELSE 'Furniture'
  END AS category
FROM numbers(10);

statement ok
CREATE OR REPLACE TABLE sales AS SELECT
  number % 500 AS sale_id,
  number % 100 AS product_id,
  number % 100 AS customer_id,
  date_add('day', floor(rand() * 10000 % 365)::int, '2021-01-01') AS sale_date,
  (rand() * 10000 % 20 + 1)::int AS quantity,
  (rand() * 10000 % 2000 * 0.01)::decimal(10, 2) AS net_paid
FROM numbers(500);

query T
explain join SELECT customer_name, segment, (SELECT SUM(net_paid) FROM sales WHERE customer_id IN (SELECT customer_id FROM customers WHERE segment = c.segment AND active = true)) FROM customers c WHERE c.customer_id IN (SELECT customer_id FROM sales WHERE net_paid > 100) LIMIT 10;
----
HashJoin: RIGHT OUTER
├── Build
│   └── HashJoin: LEFT SEMI
│       ├── Build
│       │   └── Scan: default.default.sales (#3) (read rows: 0)
│       └── Probe
│           └── Scan: default.default.customers (#0) (read rows: 100)
└── Probe
    └── HashJoin: LEFT SEMI
        ├── Build
        │   └── Scan: default.default.customers (#2) (read rows: 100)
        └── Probe
            └── HashJoin: CROSS
                ├── Build
                │   └── HashJoin: RIGHT SEMI
                │       ├── Build
                │       │   └── Scan: default.default.customers (#0) (read rows: 100)
                │       └── Probe
                │           └── Scan: default.default.sales (#3) (read rows: 500)
                └── Probe
                    └── Scan: default.default.sales (#1) (read rows: 500)


query T
explain join SELECT c.customer_name FROM customers c WHERE NOT EXISTS ( SELECT category FROM products WHERE category NOT IN ( SELECT p.category FROM sales s JOIN products p ON s.product_id = p.product_id WHERE s.customer_id = c.customer_id ) ) ORDER BY c.customer_name;
----
HashJoin: LEFT MARK
├── Build
│   └── Scan: default.default.customers (#0) (read rows: 100)
└── Probe
    └── HashJoin: RIGHT MARK
        ├── Build
        │   └── HashJoin: INNER
        │       ├── Build
        │       │   └── Scan: default.default.products (#3) (read rows: 10)
        │       └── Probe
        │           └── Scan: default.default.sales (#2) (read rows: 500)
        └── Probe
            └── HashJoin: CROSS
                ├── Build
                │   └── Scan: default.default.products (#1) (read rows: 10)
                └── Probe
                    └── Scan: default.default.customers (#0) (read rows: 100)

statement ok
drop table customers;

statement ok
drop table products;

statement ok
drop table sales;

statement ok
create OR REPLACE table t1 (a int);

statement ok
create OR REPLACE table t2 (b int);

query T
explain select date from (select *, 'year' as date from t1 left join t2 on t1.a = t2.b) where date = '';
----
EvalScalar
├── output columns: [date (#2)]
├── expressions: ['year']
├── estimated rows: 0.00
└── HashJoin
    ├── output columns: []
    ├── join type: LEFT OUTER
    ├── build keys: [t2.b (#1)]
    ├── probe keys: [t1.a (#0)]
    ├── keys is null equal: [false]
    ├── filters: []
    ├── estimated rows: 0.00
    ├── TableScan(Build)
    │   ├── table: default.default.t2
    │   ├── scan id: 1
    │   ├── output columns: [b (#1)]
    │   ├── read rows: 0
    │   ├── read size: 0
    │   ├── partitions total: 0
    │   ├── partitions scanned: 0
    │   ├── push downs: [filters: [false], limit: NONE]
    │   └── estimated rows: 0.00
    └── TableScan(Probe)
        ├── table: default.default.t1
        ├── scan id: 0
        ├── output columns: [a (#0)]
        ├── read rows: 0
        ├── read size: 0
        ├── partitions total: 0
        ├── partitions scanned: 0
        ├── push downs: [filters: [false], limit: NONE]
        └── estimated rows: 0.00


statement ok
drop table t1;

statement ok
drop table t2;

statement ok
create OR REPLACE table t1(a int, b int, c varchar(20));

statement ok
create OR REPLACE table t2(a int, b int, c varchar(20));

# scalar subquery and sort plan contains count() agg function.
query T
explain select * from t2 where c > (select c from t1 where t1.a = t2.a group by c order by count(a));
----
HashJoin
├── output columns: [t2.b (#1), t2.c (#2), t2.a (#0)]
├── join type: INNER
├── build keys: [a (#0)]
├── probe keys: [a (#3)]
├── keys is null equal: [false]
├── filters: [t2.c (#2) > scalar_subquery_5 (#5)]
├── build join filters:
│   └── filter id:0, build key:a (#0), probe targets:[a (#3)@scan1], filter type:bloom,inlist,min_max
├── estimated rows: 0.00
├── TableScan(Build)
│   ├── table: default.default.t2
│   ├── scan id: 0
│   ├── output columns: [a (#0), b (#1), c (#2)]
│   ├── read rows: 0
│   ├── read size: 0
│   ├── partitions total: 0
│   ├── partitions scanned: 0
│   ├── push downs: [filters: [], limit: NONE]
│   └── estimated rows: 0.00
└── Sort(Single)(Probe)
    ├── output columns: [count(a) (#6), t1.c (#5), t1.a (#3)]
    ├── sort keys: [count(a) ASC NULLS LAST]
    ├── estimated rows: 1.00
    └── AggregateFinal
        ├── output columns: [count(a) (#6), t1.c (#5), t1.a (#3)]
        ├── group by: [c, a]
        ├── aggregate functions: [count(a)]
        ├── estimated rows: 1.00
        └── AggregatePartial
            ├── group by: [c, a]
            ├── aggregate functions: [count(a)]
            ├── estimated rows: 1.00
            └── TableScan
                ├── table: default.default.t1
                ├── scan id: 1
                ├── output columns: [a (#3), c (#5)]
                ├── read rows: 0
                ├── read size: 0
                ├── partitions total: 0
                ├── partitions scanned: 0
                ├── push downs: [filters: [is_true(t1.a (#3) = t1.a (#3))], limit: NONE]
                ├── apply join filters: [#0]
                └── estimated rows: 0.00

query T
explain select * from t2 where c > (select c from t1 where t1.a = t2.a group by c order by count(*));
----
HashJoin
├── output columns: [t2.b (#1), t2.c (#2), t2.a (#0)]
├── join type: INNER
├── build keys: [a (#0)]
├── probe keys: [a (#3)]
├── keys is null equal: [false]
├── filters: [t2.c (#2) > scalar_subquery_5 (#5)]
├── build join filters:
│   └── filter id:0, build key:a (#0), probe targets:[a (#3)@scan1], filter type:bloom,inlist,min_max
├── estimated rows: 0.00
├── TableScan(Build)
│   ├── table: default.default.t2
│   ├── scan id: 0
│   ├── output columns: [a (#0), b (#1), c (#2)]
│   ├── read rows: 0
│   ├── read size: 0
│   ├── partitions total: 0
│   ├── partitions scanned: 0
│   ├── push downs: [filters: [], limit: NONE]
│   └── estimated rows: 0.00
└── Sort(Single)(Probe)
    ├── output columns: [COUNT(*) (#6), t1.c (#5), t1.a (#3)]
    ├── sort keys: [COUNT(*) ASC NULLS LAST]
    ├── estimated rows: 1.00
    └── AggregateFinal
        ├── output columns: [COUNT(*) (#6), t1.c (#5), t1.a (#3)]
        ├── group by: [c, a]
        ├── aggregate functions: [count()]
        ├── estimated rows: 1.00
        └── AggregatePartial
            ├── group by: [c, a]
            ├── aggregate functions: [count()]
            ├── estimated rows: 1.00
            └── Filter
                ├── output columns: [t1.a (#3), t1.c (#5)]
                ├── filters: [is_true(outer.a (#3) = outer.a (#3))]
                ├── estimated rows: 0.00
                └── TableScan
                    ├── table: default.default.t1
                    ├── scan id: 1
                    ├── output columns: [a (#3), c (#5)]
                    ├── read rows: 0
                    ├── read size: 0
                    ├── partitions total: 0
                    ├── partitions scanned: 0
                    ├── push downs: [filters: [is_true(t1.a (#3) = t1.a (#3))], limit: NONE]
                    ├── apply join filters: [#0]
                    └── estimated rows: 0.00

query T
explain insert into t2 select * from t1;
----
InsertPlan (subquery):
├── table: default.default.t2
├── inserted columns: [t2.a (#0),t2.b (#1),t2.c (#2)]
├── overwrite: false
└── Scan
    ├── table: default.t1 (#0)
    ├── filters: []
    ├── order by: []
    └── limit: NONE


statement ok
drop table t1;

statement ok
drop table t2;

statement ok
create or replace table date_sub_query_test(id bigint null, test_time timestamp null);

query T
explain select * from date_sub_query_test where test_time >= (select to_timestamp('2024-01-01 00:00:00'));
----
TableScan
├── table: default.default.date_sub_query_test
├── scan id: 0
├── output columns: [id (#0), test_time (#1)]
├── read rows: 0
├── read size: 0
├── partitions total: 0
├── partitions scanned: 0
├── push downs: [filters: [is_true(date_sub_query_test.test_time (#1) >= '2024-01-01 00:00:00.000000')], limit: NONE]
└── estimated rows: 0.00

statement ok
drop table date_sub_query_test;

query T
explain select * from numbers(0);
----
TableScan
├── table: default.system.numbers
├── scan id: 0
├── output columns: [number (#0)]
├── read rows: 0
├── read size: 0
├── partitions total: 1
├── partitions scanned: 1
├── push downs: [filters: [], limit: NONE]
└── estimated rows: 0.00

query T
explain select * from numbers(10);
----
TableScan
├── table: default.system.numbers
├── scan id: 0
├── output columns: [number (#0)]
├── read rows: 10
├── read size: < 1 KiB
├── partitions total: 1
├── partitions scanned: 1
├── push downs: [filters: [], limit: NONE]
└── estimated rows: 10.00

query T
explain select * from numbers(10000);
----
TableScan
├── table: default.system.numbers
├── scan id: 0
├── output columns: [number (#0)]
├── read rows: 10000
├── read size: 78.12 KiB
├── partitions total: 1
├── partitions scanned: 1
├── push downs: [filters: [], limit: NONE]
└── estimated rows: 10000.00

query T
explain select * from numbers(10000000);
----
TableScan
├── table: default.system.numbers
├── scan id: 0
├── output columns: [number (#0)]
├── read rows: 10000000
├── read size: 76.29 MiB
├── partitions total: 153
├── partitions scanned: 153
├── push downs: [filters: [], limit: NONE]
└── estimated rows: 10000000.00

query T
explain select * from numbers(10000000000);
----
TableScan
├── table: default.system.numbers
├── scan id: 0
├── output columns: [number (#0)]
├── read rows: 10000000000
├── read size: 74.51 GiB
├── partitions total: 152588
├── partitions scanned: 152588
├── push downs: [filters: [], limit: NONE]
└── estimated rows: 10000000000.00

query T
explain select * from numbers(10000000000000);
----
TableScan
├── table: default.system.numbers
├── scan id: 0
├── output columns: [number (#0)]
├── read rows: 10000000000000
├── read size: 72.76 TiB
├── partitions total: 152587891
├── partitions scanned: 152587891
├── push downs: [filters: [], limit: NONE]
└── estimated rows: 10000000000000.00

query T
explain select * from numbers(10000000000000000);
----
TableScan
├── table: default.system.numbers
├── scan id: 0
├── output columns: [number (#0)]
├── read rows: 10000000000000000
├── read size: 71.05 PiB
├── partitions total: 152587890626
├── partitions scanned: 152587890626
├── push downs: [filters: [], limit: NONE]
└── estimated rows: 10000000000000000.00



statement ok
CREATE OR REPLACE TABLE orders_placed (order_id INT, customer_id INT, order_amount FLOAT, order_date DATE);

query T
EXPLAIN syntax
INSERT FIRST
WHEN order_amount > 1000 THEN INTO cat.db1.t1(order_id, update_note) VALUES (order_id, 'PriorityHandling')
WHEN order_amount > 500 THEN INTO cat2.db2.t2 VALUES (order_id, 'ExpressHandling')
WHEN order_amount > 100 THEN
   INTO cat3.db3.t3 VALUES (order_id, 'StandardHandling')
   INTO cat3.db3.t4 VALUES (order_id, 'StandardHandling')
ELSE INTO processing_updates VALUES (order_id, 'ReviewNeeded')
SELECT order_id, order_amount FROM orders_placed;
----
INSERT FIRST WHEN order_amount > 1000 THEN INTO cat.db1.t1 (order_id, update_note) VALUES  (order_id, 'PriorityHandling')  WHEN order_amount > 500 THEN INTO cat2.db2.t2 VALUES  (order_id, 'ExpressHandling')  WHEN order_amount > 100 THEN INTO cat3.db3.t3 VALUES  (order_id, 'StandardHandling') INTO cat3.db3.t4 VALUES  (order_id, 'StandardHandling')  ELSE INTO processing_updates VALUES  (order_id, 'ReviewNeeded')  SELECT order_id, order_amount FROM orders_placed

query T
EXPLAIN syntax
INSERT ALL
   INTO cat.db1.t1 VALUES (order_id, 'PriorityHandling')
   INTO cat3.db3.t3 VALUES (order_id, 'StandardHandling')
   INTO cat3.db3.t4 VALUES (order_id, 'StandardHandling')
SELECT order_id, order_amount FROM orders_placed;
----
INSERT ALL INTO cat.db1.t1 VALUES  (order_id, 'PriorityHandling') INTO cat3.db3.t3 VALUES  (order_id, 'StandardHandling') INTO cat3.db3.t4 VALUES  (order_id, 'StandardHandling') SELECT order_id, order_amount FROM orders_placed

query T
EXPLAIN syntax
INSERT OVERWRITE ALL
   INTO cat.db1.t1 VALUES (order_id, 'PriorityHandling')
   INTO cat3.db3.t3 VALUES (order_id, 'StandardHandling')
   INTO cat3.db3.t4 VALUES (order_id, 'StandardHandling')
SELECT order_id, order_amount FROM orders_placed;
----
INSERT OVERWRITE ALL INTO cat.db1.t1 VALUES  (order_id, 'PriorityHandling') INTO cat3.db3.t3 VALUES  (order_id, 'StandardHandling') INTO cat3.db3.t4 VALUES  (order_id, 'StandardHandling') SELECT order_id, order_amount FROM orders_placed

statement ok
drop table  orders_placed

# Test Tuple Statistics
statement ok
CREATE OR REPLACE TABLE t(a TUPLE(INT, INT));

statement ok
INSERT INTO t VALUES((1, 2)), ((3, 4));

query T
EXPLAIN SELECT * FROM t WHERE a.1 > 0;
----
TableScan
├── table: default.default.t
├── scan id: 0
├── output columns: [a (#0)]
├── read rows: 2
├── read size: < 1 KiB
├── partitions total: 1
├── partitions scanned: 1
├── pruning stats: [segments: <range pruning: 1 to 1 cost: <slt:ignore>>, blocks: <range pruning: 1 to 1 cost: <slt:ignore>>]
├── push downs: [filters: [is_true(t.a:"1" (#2) > 0)], limit: NONE]
└── estimated rows: 2.00

query T
EXPLAIN SELECT * FROM t WHERE a.1 > 1;
----
TableScan
├── table: default.default.t
├── scan id: 0
├── output columns: [a (#0)]
├── read rows: 2
├── read size: < 1 KiB
├── partitions total: 1
├── partitions scanned: 1
├── pruning stats: [segments: <range pruning: 1 to 1 cost: <slt:ignore>>, blocks: <range pruning: 1 to 1 cost: <slt:ignore>>]
├── push downs: [filters: [is_true(t.a:"1" (#2) > 1)], limit: NONE]
└── estimated rows: 1.00

query T
EXPLAIN SELECT * FROM t WHERE a.2 > 1;
----
TableScan
├── table: default.default.t
├── scan id: 0
├── output columns: [a (#0)]
├── read rows: 2
├── read size: < 1 KiB
├── partitions total: 1
├── partitions scanned: 1
├── pruning stats: [segments: <range pruning: 1 to 1 cost: <slt:ignore>>, blocks: <range pruning: 1 to 1 cost: <slt:ignore>>]
├── push downs: [filters: [is_true(t.a:"2" (#1) > 1)], limit: NONE]
└── estimated rows: 2.00

statement ok
DROP TABLE IF EXISTS t;

query T
EXPLAIN SELECT a.number FROM numbers(10) AS a INNER JOIN (SELECT * FROM numbers(10) WHERE NOT number) AS b ON a.number = b.number
----
HashJoin
├── output columns: [a.number (#0)]
├── join type: INNER
├── build keys: [numbers.number (#1)]
├── probe keys: [a.number (#0)]
├── keys is null equal: [false]
├── filters: []
├── build join filters:
│   └── filter id:0, build key:numbers.number (#1), probe targets:[a.number (#0)@scan0], filter type:bloom,inlist,min_max
├── estimated rows: 25.00
├── Filter(Build)
│   ├── output columns: [numbers.number (#1)]
│   ├── filters: [NOT CAST(numbers.number (#1) AS Boolean)]
│   ├── estimated rows: 5.00
│   └── TableScan
│       ├── table: default.system.numbers
│       ├── scan id: 1
│       ├── output columns: [number (#1)]
│       ├── read rows: 10
│       ├── read size: < 1 KiB
│       ├── partitions total: 1
│       ├── partitions scanned: 1
│       ├── push downs: [filters: [NOT CAST(numbers.number (#1) AS Boolean)], limit: NONE]
│       └── estimated rows: 10.00
└── Filter(Probe)
    ├── output columns: [a.number (#0)]
    ├── filters: [NOT CAST(a.number (#0) AS Boolean)]
    ├── estimated rows: 5.00
    └── TableScan
        ├── table: default.system.numbers
        ├── scan id: 0
        ├── output columns: [number (#0)]
        ├── read rows: 10
        ├── read size: < 1 KiB
        ├── partitions total: 1
        ├── partitions scanned: 1
        ├── push downs: [filters: [NOT CAST(numbers.number (#0) AS Boolean)], limit: NONE]
        ├── apply join filters: [#0]
        └── estimated rows: 10.00

# issue: https://github.com/databendlabs/databend/issues/17162
query T
EXPLAIN WITH RECURSIVE aoc10_input(i) AS (SELECT '\n89010123\n78121874\n87430965\n96549874\n45678903\n32019012\n01329801\n10456732\n'), lines(y, line, rest) AS (SELECT 0::UInt64, substr(i, 1, position('\n' IN i) - 1), substr(i, position('\n' IN i) + 1) FROM aoc10_input UNION ALL SELECT y + 1::UInt64, substr(rest, 1, position('\n' IN rest) - 1), substr(rest, position('\n' IN rest) + 1) FROM lines WHERE position('\n' IN rest) > 0), field(x, y, v) AS (SELECT x::UInt64 AS x, y, (ascii(substr(line, x::Int64, 1)) - 48)::UInt64 AS v FROM (SELECT * FROM lines l WHERE line <> '') s, LATERAL generate_series(1, length(line)) g(x)), paths(x, y, v, sx, sy) AS (SELECT x, y, 9::UInt64, x, y FROM field WHERE v = 9 UNION ALL SELECT f.x, f.y, f.v, p.sx, p.sy FROM field f JOIN paths p ON f.v = p.v - 1 AND p.v > 0 AND ((f.x = p.x AND abs(f.y - p.y) = 1) OR (f.y = p.y AND abs(f.x - p.x) = 1))), results AS (SELECT * FROM paths WHERE v = 0), part1 AS (SELECT DISTINCT * FROM results) SELECT (SELECT count(*) FROM part1) AS part1, (SELECT count(*) FROM results) AS part2;
----
EvalScalar
├── output columns: [part1 (#92), part2 (#93)]
├── expressions: [scalar_subquery_45 (#45), scalar_subquery_91 (#91)]
├── estimated rows: 1.00
└── HashJoin
    ├── output columns: [COUNT(*) (#45), COUNT(*) (#91)]
    ├── join type: LEFT SINGLE
    ├── build keys: []
    ├── probe keys: []
    ├── keys is null equal: []
    ├── filters: []
    ├── estimated rows: 1.00
    ├── AggregateFinal(Build)
    │   ├── output columns: [COUNT(*) (#91)]
    │   ├── group by: []
    │   ├── aggregate functions: [count()]
    │   ├── estimated rows: 1.00
    │   └── AggregatePartial
    │       ├── group by: []
    │       ├── aggregate functions: [count()]
    │       ├── estimated rows: 1.00
    │       └── Filter
    │           ├── output columns: []
    │           ├── filters: [paths.v (#88) = 0]
    │           ├── estimated rows: 0.15
    │           └── UnionAll(recursive cte)
    │               ├── output columns: [x (#86), y (#87), 9 (#88), x (#89), y (#90)]
    │               ├── estimated rows: 0.30
    │               ├── EvalScalar
    │               │   ├── output columns: [0 (#56), x (#61), 9 (#63)]
    │               │   ├── expressions: [9]
    │               │   ├── estimated rows: 0.30
    │               │   └── EvalScalar
    │               │       ├── output columns: [0 (#56), x (#61)]
    │               │       ├── expressions: [CAST(g.x (#60) AS UInt64 NULL)]
    │               │       ├── estimated rows: 0.30
    │               │       └── EvalScalar
    │               │           ├── output columns: [0 (#56), generate_series(1, length(line)) (#60)]
    │               │           ├── expressions: [get(1)(generate_series(1, length(s.line (#57))) (#59))]
    │               │           ├── estimated rows: 0.30
    │               │           └── Filter
    │               │               ├── output columns: [0 (#56), generate_series(1, length(s.line (#57))) (#59)]
    │               │               ├── filters: [is_true(CAST(ascii(substr(CAST(s.line (#57) AS String NULL), get(1)(generate_series(1, length(s.line (#57))) (#59)), 1)) - 48 AS UInt64 NULL) = 9)]
    │               │               ├── estimated rows: 0.30
    │               │               └── ProjectSet
    │               │                   ├── output columns: [0 (#56), SUBSTRING(i FROM 1 FOR POSITION('\n' IN i) - 1) (#57), generate_series(1, length(s.line (#57))) (#59)]
    │               │                   ├── estimated rows: 1.50
    │               │                   ├── set returning functions: generate_series(1, length(s.line (#57)))
    │               │                   └── Filter
    │               │                       ├── output columns: [0 (#56), SUBSTRING(i FROM 1 FOR POSITION('\n' IN i) - 1) (#57)]
    │               │                       ├── filters: [l.line (#57) <> '']
    │               │                       ├── estimated rows: 0.50
    │               │                       └── UnionAll(recursive cte)
    │               │                           ├── output columns: [0 (#56), SUBSTRING(i FROM 1 FOR POSITION('\n' IN i) - 1) (#57), SUBSTRING(i FROM POSITION('\n' IN i) + 1) (#58)]
    │               │                           ├── estimated rows: 1.00
    │               │                           ├── EvalScalar
    │               │                           │   ├── output columns: [0 (#47), SUBSTRING(i FROM 1 FOR POSITION('\n' IN i) - 1) (#48), SUBSTRING(i FROM POSITION('\n' IN i) + 1) (#49)]
    │               │                           │   ├── expressions: [0, substr(aoc10_input.i (#46), 1, CAST(locate('\n', aoc10_input.i (#46)) - 1 AS UInt64)), substr(aoc10_input.i (#46), CAST(locate('\n', aoc10_input.i (#46)) + 1 AS Int64))]
    │               │                           │   ├── estimated rows: 1.00
    │               │                           │   └── EvalScalar
    │               │                           │       ├── output columns: ['\n89010123\n78121874\n87430965\n96549874\n45678903\n32019012\n01329801\n10456732\n' (#46)]
    │               │                           │       ├── expressions: ['\n89010123\n78121874\n87430965\n96549874\n45678903\n32019012\n01329801\n10456732\n']
    │               │                           │       ├── estimated rows: 1.00
    │               │                           │       └── DummyTableScan
    │               │                           └── EvalScalar
    │               │                               ├── output columns: [y + 1::UInt64 (#53), SUBSTRING(rest FROM 1 FOR POSITION('\n' IN rest) - 1) (#54), SUBSTRING(rest FROM POSITION('\n' IN rest) + 1) (#55)]
    │               │                               ├── expressions: [lines.y (#50) + 1, substr(lines.rest (#52), 1, CAST(locate('\n', lines.rest (#52)) - 1 AS UInt64)), substr(lines.rest (#52), CAST(locate('\n', lines.rest (#52)) + 1 AS Int64))]
    │               │                               ├── estimated rows: 0.00
    │               │                               └── Filter
    │               │                                   ├── output columns: [y (#50), rest (#52)]
    │               │                                   ├── filters: [locate('\n', lines.rest (#52)) > 0]
    │               │                                   ├── estimated rows: 0.00
    │               │                                   └── RecursiveCteScan
    │               └── Filter
    │                   ├── output columns: [0 (#74), x (#79), v (#80), sx (#84), sy (#85)]
    │                   ├── filters: [f.x (#79) = p.x (#81) and abs(f.y (#74) - p.y (#82)) = 1 or f.y (#74) = p.y (#82) and abs(f.x (#79) - p.x (#81)) = 1]
    │                   ├── estimated rows: 0.00
    │                   └── HashJoin
    │                       ├── output columns: [0 (#74), x (#79), v (#80), x (#81), y (#82), sx (#84), sy (#85)]
    │                       ├── join type: INNER
    │                       ├── build keys: [CAST(p.v (#83) - 1 AS Int64 NULL)]
    │                       ├── probe keys: [CAST(f.v (#80) AS Int64 NULL)]
    │                       ├── keys is null equal: [false]
    │                       ├── filters: []
    │                       ├── estimated rows: 0.00
    │                       ├── Filter(Build)
    │                       │   ├── output columns: [x (#81), y (#82), v (#83), sx (#84), sy (#85)]
    │                       │   ├── filters: [p.v (#83) > 0]
    │                       │   ├── estimated rows: 0.00
    │                       │   └── RecursiveCteScan
    │                       └── EvalScalar(Probe)
    │                           ├── output columns: [0 (#74), x (#79), v (#80)]
    │                           ├── expressions: [CAST(g.x (#78) AS UInt64 NULL), CAST(ascii(substr(CAST(s.line (#75) AS String NULL), g.x (#78), 1)) - 48 AS UInt64 NULL)]
    │                           ├── estimated rows: 1.50
    │                           └── EvalScalar
    │                               ├── output columns: [0 (#74), SUBSTRING(i FROM 1 FOR POSITION('\n' IN i) - 1) (#75), generate_series(1, length(line)) (#78)]
    │                               ├── expressions: [get(1)(generate_series(1, length(s.line (#75))) (#77))]
    │                               ├── estimated rows: 1.50
    │                               └── ProjectSet
    │                                   ├── output columns: [0 (#74), SUBSTRING(i FROM 1 FOR POSITION('\n' IN i) - 1) (#75), generate_series(1, length(s.line (#75))) (#77)]
    │                                   ├── estimated rows: 1.50
    │                                   ├── set returning functions: generate_series(1, length(s.line (#75)))
    │                                   └── Filter
    │                                       ├── output columns: [0 (#74), SUBSTRING(i FROM 1 FOR POSITION('\n' IN i) - 1) (#75)]
    │                                       ├── filters: [l.line (#75) <> '']
    │                                       ├── estimated rows: 0.50
    │                                       └── UnionAll(recursive cte)
    │                                           ├── output columns: [0 (#74), SUBSTRING(i FROM 1 FOR POSITION('\n' IN i) - 1) (#75), SUBSTRING(i FROM POSITION('\n' IN i) + 1) (#76)]
    │                                           ├── estimated rows: 1.00
    │                                           ├── EvalScalar
    │                                           │   ├── output columns: [0 (#65), SUBSTRING(i FROM 1 FOR POSITION('\n' IN i) - 1) (#66), SUBSTRING(i FROM POSITION('\n' IN i) + 1) (#67)]
    │                                           │   ├── expressions: [0, substr(aoc10_input.i (#64), 1, CAST(locate('\n', aoc10_input.i (#64)) - 1 AS UInt64)), substr(aoc10_input.i (#64), CAST(locate('\n', aoc10_input.i (#64)) + 1 AS Int64))]
    │                                           │   ├── estimated rows: 1.00
    │                                           │   └── EvalScalar
    │                                           │       ├── output columns: ['\n89010123\n78121874\n87430965\n96549874\n45678903\n32019012\n01329801\n10456732\n' (#64)]
    │                                           │       ├── expressions: ['\n89010123\n78121874\n87430965\n96549874\n45678903\n32019012\n01329801\n10456732\n']
    │                                           │       ├── estimated rows: 1.00
    │                                           │       └── DummyTableScan
    │                                           └── EvalScalar
    │                                               ├── output columns: [y + 1::UInt64 (#71), SUBSTRING(rest FROM 1 FOR POSITION('\n' IN rest) - 1) (#72), SUBSTRING(rest FROM POSITION('\n' IN rest) + 1) (#73)]
    │                                               ├── expressions: [lines.y (#68) + 1, substr(lines.rest (#70), 1, CAST(locate('\n', lines.rest (#70)) - 1 AS UInt64)), substr(lines.rest (#70), CAST(locate('\n', lines.rest (#70)) + 1 AS Int64))]
    │                                               ├── estimated rows: 0.00
    │                                               └── Filter
    │                                                   ├── output columns: [y (#68), rest (#70)]
    │                                                   ├── filters: [locate('\n', lines.rest (#70)) > 0]
    │                                                   ├── estimated rows: 0.00
    │                                                   └── RecursiveCteScan
    └── HashJoin(Probe)
        ├── output columns: [COUNT(*) (#45)]
        ├── join type: LEFT SINGLE
        ├── build keys: []
        ├── probe keys: []
        ├── keys is null equal: []
        ├── filters: []
        ├── estimated rows: 1.00
        ├── AggregateFinal(Build)
        │   ├── output columns: [COUNT(*) (#45)]
        │   ├── group by: []
        │   ├── aggregate functions: [count()]
        │   ├── estimated rows: 1.00
        │   └── AggregatePartial
        │       ├── group by: []
        │       ├── aggregate functions: [count()]
        │       ├── estimated rows: 1.00
        │       └── AggregateFinal
        │           ├── output columns: [x (#40), y (#41), 9 (#42), x (#43), y (#44)]
        │           ├── group by: [x, y, 9, x, y]
        │           ├── aggregate functions: []
        │           ├── estimated rows: 1.00
        │           └── AggregatePartial
        │               ├── group by: [x, y, 9, x, y]
        │               ├── aggregate functions: []
        │               ├── estimated rows: 1.00
        │               └── Filter
        │                   ├── output columns: [x (#40), y (#41), 9 (#42), x (#43), y (#44)]
        │                   ├── filters: [results.v (#42) = 0]
        │                   ├── estimated rows: 0.15
        │                   └── UnionAll(recursive cte)
        │                       ├── output columns: [x (#40), y (#41), 9 (#42), x (#43), y (#44)]
        │                       ├── estimated rows: 0.30
        │                       ├── EvalScalar
        │                       │   ├── output columns: [0 (#10), x (#15), 9 (#17)]
        │                       │   ├── expressions: [9]
        │                       │   ├── estimated rows: 0.30
        │                       │   └── EvalScalar
        │                       │       ├── output columns: [0 (#10), x (#15)]
        │                       │       ├── expressions: [CAST(g.x (#14) AS UInt64 NULL)]
        │                       │       ├── estimated rows: 0.30
        │                       │       └── EvalScalar
        │                       │           ├── output columns: [0 (#10), generate_series(1, length(line)) (#14)]
        │                       │           ├── expressions: [get(1)(generate_series(1, length(s.line (#11))) (#13))]
        │                       │           ├── estimated rows: 0.30
        │                       │           └── Filter
        │                       │               ├── output columns: [0 (#10), generate_series(1, length(s.line (#11))) (#13)]
        │                       │               ├── filters: [is_true(CAST(ascii(substr(CAST(s.line (#11) AS String NULL), get(1)(generate_series(1, length(s.line (#11))) (#13)), 1)) - 48 AS UInt64 NULL) = 9)]
        │                       │               ├── estimated rows: 0.30
        │                       │               └── ProjectSet
        │                       │                   ├── output columns: [0 (#10), SUBSTRING(i FROM 1 FOR POSITION('\n' IN i) - 1) (#11), generate_series(1, length(s.line (#11))) (#13)]
        │                       │                   ├── estimated rows: 1.50
        │                       │                   ├── set returning functions: generate_series(1, length(s.line (#11)))
        │                       │                   └── Filter
        │                       │                       ├── output columns: [0 (#10), SUBSTRING(i FROM 1 FOR POSITION('\n' IN i) - 1) (#11)]
        │                       │                       ├── filters: [l.line (#11) <> '']
        │                       │                       ├── estimated rows: 0.50
        │                       │                       └── UnionAll(recursive cte)
        │                       │                           ├── output columns: [0 (#10), SUBSTRING(i FROM 1 FOR POSITION('\n' IN i) - 1) (#11), SUBSTRING(i FROM POSITION('\n' IN i) + 1) (#12)]
        │                       │                           ├── estimated rows: 1.00
        │                       │                           ├── EvalScalar
        │                       │                           │   ├── output columns: [0 (#1), SUBSTRING(i FROM 1 FOR POSITION('\n' IN i) - 1) (#2), SUBSTRING(i FROM POSITION('\n' IN i) + 1) (#3)]
        │                       │                           │   ├── expressions: [0, substr(aoc10_input.i (#0), 1, CAST(locate('\n', aoc10_input.i (#0)) - 1 AS UInt64)), substr(aoc10_input.i (#0), CAST(locate('\n', aoc10_input.i (#0)) + 1 AS Int64))]
        │                       │                           │   ├── estimated rows: 1.00
        │                       │                           │   └── EvalScalar
        │                       │                           │       ├── output columns: ['\n89010123\n78121874\n87430965\n96549874\n45678903\n32019012\n01329801\n10456732\n' (#0)]
        │                       │                           │       ├── expressions: ['\n89010123\n78121874\n87430965\n96549874\n45678903\n32019012\n01329801\n10456732\n']
        │                       │                           │       ├── estimated rows: 1.00
        │                       │                           │       └── DummyTableScan
        │                       │                           └── EvalScalar
        │                       │                               ├── output columns: [y + 1::UInt64 (#7), SUBSTRING(rest FROM 1 FOR POSITION('\n' IN rest) - 1) (#8), SUBSTRING(rest FROM POSITION('\n' IN rest) + 1) (#9)]
        │                       │                               ├── expressions: [lines.y (#4) + 1, substr(lines.rest (#6), 1, CAST(locate('\n', lines.rest (#6)) - 1 AS UInt64)), substr(lines.rest (#6), CAST(locate('\n', lines.rest (#6)) + 1 AS Int64))]
        │                       │                               ├── estimated rows: 0.00
        │                       │                               └── Filter
        │                       │                                   ├── output columns: [y (#4), rest (#6)]
        │                       │                                   ├── filters: [locate('\n', lines.rest (#6)) > 0]
        │                       │                                   ├── estimated rows: 0.00
        │                       │                                   └── RecursiveCteScan
        │                       └── Filter
        │                           ├── output columns: [0 (#28), x (#33), v (#34), sx (#38), sy (#39)]
        │                           ├── filters: [f.x (#33) = p.x (#35) and abs(f.y (#28) - p.y (#36)) = 1 or f.y (#28) = p.y (#36) and abs(f.x (#33) - p.x (#35)) = 1]
        │                           ├── estimated rows: 0.00
        │                           └── HashJoin
        │                               ├── output columns: [0 (#28), x (#33), v (#34), x (#35), y (#36), sx (#38), sy (#39)]
        │                               ├── join type: INNER
        │                               ├── build keys: [CAST(p.v (#37) - 1 AS Int64 NULL)]
        │                               ├── probe keys: [CAST(f.v (#34) AS Int64 NULL)]
        │                               ├── keys is null equal: [false]
        │                               ├── filters: []
        │                               ├── estimated rows: 0.00
        │                               ├── Filter(Build)
        │                               │   ├── output columns: [x (#35), y (#36), v (#37), sx (#38), sy (#39)]
        │                               │   ├── filters: [p.v (#37) > 0]
        │                               │   ├── estimated rows: 0.00
        │                               │   └── RecursiveCteScan
        │                               └── EvalScalar(Probe)
        │                                   ├── output columns: [0 (#28), x (#33), v (#34)]
        │                                   ├── expressions: [CAST(g.x (#32) AS UInt64 NULL), CAST(ascii(substr(CAST(s.line (#29) AS String NULL), g.x (#32), 1)) - 48 AS UInt64 NULL)]
        │                                   ├── estimated rows: 1.50
        │                                   └── EvalScalar
        │                                       ├── output columns: [0 (#28), SUBSTRING(i FROM 1 FOR POSITION('\n' IN i) - 1) (#29), generate_series(1, length(line)) (#32)]
        │                                       ├── expressions: [get(1)(generate_series(1, length(s.line (#29))) (#31))]
        │                                       ├── estimated rows: 1.50
        │                                       └── ProjectSet
        │                                           ├── output columns: [0 (#28), SUBSTRING(i FROM 1 FOR POSITION('\n' IN i) - 1) (#29), generate_series(1, length(s.line (#29))) (#31)]
        │                                           ├── estimated rows: 1.50
        │                                           ├── set returning functions: generate_series(1, length(s.line (#29)))
        │                                           └── Filter
        │                                               ├── output columns: [0 (#28), SUBSTRING(i FROM 1 FOR POSITION('\n' IN i) - 1) (#29)]
        │                                               ├── filters: [l.line (#29) <> '']
        │                                               ├── estimated rows: 0.50
        │                                               └── UnionAll(recursive cte)
        │                                                   ├── output columns: [0 (#28), SUBSTRING(i FROM 1 FOR POSITION('\n' IN i) - 1) (#29), SUBSTRING(i FROM POSITION('\n' IN i) + 1) (#30)]
        │                                                   ├── estimated rows: 1.00
        │                                                   ├── EvalScalar
        │                                                   │   ├── output columns: [0 (#19), SUBSTRING(i FROM 1 FOR POSITION('\n' IN i) - 1) (#20), SUBSTRING(i FROM POSITION('\n' IN i) + 1) (#21)]
        │                                                   │   ├── expressions: [0, substr(aoc10_input.i (#18), 1, CAST(locate('\n', aoc10_input.i (#18)) - 1 AS UInt64)), substr(aoc10_input.i (#18), CAST(locate('\n', aoc10_input.i (#18)) + 1 AS Int64))]
        │                                                   │   ├── estimated rows: 1.00
        │                                                   │   └── EvalScalar
        │                                                   │       ├── output columns: ['\n89010123\n78121874\n87430965\n96549874\n45678903\n32019012\n01329801\n10456732\n' (#18)]
        │                                                   │       ├── expressions: ['\n89010123\n78121874\n87430965\n96549874\n45678903\n32019012\n01329801\n10456732\n']
        │                                                   │       ├── estimated rows: 1.00
        │                                                   │       └── DummyTableScan
        │                                                   └── EvalScalar
        │                                                       ├── output columns: [y + 1::UInt64 (#25), SUBSTRING(rest FROM 1 FOR POSITION('\n' IN rest) - 1) (#26), SUBSTRING(rest FROM POSITION('\n' IN rest) + 1) (#27)]
        │                                                       ├── expressions: [lines.y (#22) + 1, substr(lines.rest (#24), 1, CAST(locate('\n', lines.rest (#24)) - 1 AS UInt64)), substr(lines.rest (#24), CAST(locate('\n', lines.rest (#24)) + 1 AS Int64))]
        │                                                       ├── estimated rows: 0.00
        │                                                       └── Filter
        │                                                           ├── output columns: [y (#22), rest (#24)]
        │                                                           ├── filters: [locate('\n', lines.rest (#24)) > 0]
        │                                                           ├── estimated rows: 0.00
        │                                                           └── RecursiveCteScan
        └── DummyTableScan(Probe)
